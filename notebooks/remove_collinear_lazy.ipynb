{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define a base directory for the dataset\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    # Code is running in Google Colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    base_dir = Path('/content/drive/My Drive/Supervised-Project/Data')\n",
    "    !pip install numpy seaborn matplotlib scipy pandas ts2vg scikit-image pyfeats scikit-learn==1.2.0 lazypredict dask[dataframe] antropy pywt\n",
    "else:\n",
    "    # Code is running locally\n",
    "    base_dir = Path('Data/')  # Adjust to your local relative path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's load the training data\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter\n",
    "import pandas as pd\n",
    "from features.wavelet_decomposition import extract_wavelet_energy_features\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from lazypredict.Supervised import CLASSIFIERS\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import welch\n",
    "import antropy as ant\n",
    "import pywt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = Path(\"../data/train/\")\n",
    "training_data = [(np.load(ROOT_PATH / f\"data_{i}.npy\"),np.load(ROOT_PATH / f\"target_{i}.npy\")) for i in range(4)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    return butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def reshape_array_into_windows(x, sample_rate, window_duration_in_seconds):\n",
    "    \"\"\"\n",
    "    Reshape the data into an array of shape (C, T, window) where 'window' contains\n",
    "    the points corresponding to 'window_duration' seconds of data.\n",
    "\n",
    "    Parameters:\n",
    "    x (numpy array): The input data array.\n",
    "    sample_rate (int): The number of samples per second.\n",
    "    window_duration_in_seconds (float): The duration of each window in seconds.\n",
    "\n",
    "    Returns:\n",
    "    reshaped_x (numpy array): The reshaped array with shape (C, T, window).\n",
    "    \"\"\"\n",
    "    # Calculate the number of samples in one window\n",
    "    window_size = int(window_duration_in_seconds * sample_rate)\n",
    "    \n",
    "    # Ensure the total length of x is a multiple of window_size\n",
    "    total_samples = x.shape[-1]\n",
    "    if total_samples % window_size != 0:\n",
    "        # Truncate or pad x to make it divisible by window_size\n",
    "        x = x[..., :total_samples - (total_samples % window_size)]\n",
    "    # Reshape x into (C, T, window)\n",
    "    reshaped_x = x.reshape(x.shape[0], -1, window_size)\n",
    "\n",
    "    return reshaped_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time domain features\n",
    "def extract_time_domain_features(data, return_type='dataframe'):\n",
    "    \"\"\"\n",
    "    Extracts time-domain features from EEG data.\n",
    "    Parameters:\n",
    "    data (numpy.ndarray): A 2D or 3D array where each row (or each slice in the case of 3D) represents a 2-second window of EEG data sampled at 250 Hz (i.e., each row has 500 data points).\n",
    "    return_type (str): The type of the return value, either 'dataframe' or 'numpy'.\n",
    "    Returns:\n",
    "    pandas.DataFrame or numpy.ndarray: A DataFrame or ndarray containing the following time-domain features for each row (or slice) of the input data:\n",
    "        - amplitude: The difference between the maximum and minimum values.\n",
    "        - mean: The mean value.\n",
    "        - max: The maximum value.\n",
    "        - min: The minimum value.\n",
    "        - stdev: The standard deviation.\n",
    "        - skewness: The skewness of the data.\n",
    "        - kurtosis: The kurtosis of the data.\n",
    "        - hjorth_activity: The Hjorth activity parameter.\n",
    "        - hjorth_mobility: The Hjorth mobility parameter.\n",
    "        - hjorth_complexity: The Hjorth complexity parameter.\n",
    "    \"\"\"\n",
    "\n",
    "    is_3d = data.ndim == 3\n",
    "\n",
    "    amplitude = np.max(data, axis=-1) - np.min(data, axis=-1)\n",
    "    mean_values = np.mean(data, axis=-1)\n",
    "    max_values = np.max(data, axis=-1)\n",
    "    min_values = np.min(data, axis=-1)\n",
    "    stdev_values = np.std(data, axis=-1)\n",
    "    skewness_values = skew(data, axis=-1)\n",
    "    kurtosis_values = kurtosis(data, axis=-1)\n",
    "\n",
    "    # Hjorth parameters\n",
    "    def hjorth_parameters(data):\n",
    "        first_deriv = np.diff(data, axis=-1)\n",
    "        second_deriv = np.diff(first_deriv, axis=-1)\n",
    "        var_zero = np.var(data, axis=-1)\n",
    "        var_d1 = np.var(first_deriv, axis=-1)\n",
    "        var_d2 = np.var(second_deriv, axis=-1)\n",
    "        activity = var_zero\n",
    "        mobility = np.sqrt(var_d1 / var_zero)\n",
    "        complexity = np.sqrt(var_d2 / var_d1) / mobility\n",
    "        return activity, mobility, complexity\n",
    "\n",
    "    hjorth_activity, hjorth_mobility, hjorth_complexity = hjorth_parameters(data)\n",
    "\n",
    "    features = {\n",
    "        \"amplitude\": amplitude,\n",
    "        \"mean\": mean_values,\n",
    "        \"max\": max_values,\n",
    "        \"min\": min_values,\n",
    "        \"stdev\": stdev_values,\n",
    "        \"skewness\": skewness_values,\n",
    "        \"kurtosis\": kurtosis_values,\n",
    "        \"hjorth_activity\": hjorth_activity,\n",
    "        \"hjorth_mobility\": hjorth_mobility,\n",
    "        \"hjorth_complexity\": hjorth_complexity,\n",
    "    }\n",
    "\n",
    "    if not is_3d:\n",
    "        for key in features:\n",
    "            features[key] = features[key].reshape(-1)\n",
    "\n",
    "    if return_type == 'dataframe':\n",
    "        return pd.DataFrame(features)\n",
    "    elif return_type == 'numpy':\n",
    "        return features\n",
    "    else:\n",
    "       raise ValueError(\"return_type must be either 'dataframe' or 'numpy'\")\n",
    "    \n",
    "\n",
    "# Extract frequency domain features\n",
    "def extract_frequency_domain_features(data, fs=250):\n",
    "    \"\"\"\n",
    "    Extracts frequency domain features from EEG signal data.\n",
    "    Parameters:\n",
    "    data (np.ndarray): A NumPy array where each row represents a 2-second window of the EEG signal, \n",
    "                       with each row containing 500 data points.\n",
    "    fs (int): Sampling frequency of the EEG signal. Default is 250 Hz.\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the extracted frequency domain features.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define frequency bands\n",
    "    bands = {\n",
    "        'delta': (0.5, 4),\n",
    "        'theta': (4, 8),\n",
    "        'alpha': (8, 12),\n",
    "        'beta': (12, 30),\n",
    "        'gamma': (30, 40)\n",
    "    }\n",
    "\n",
    "    features = []\n",
    "\n",
    "    for window in data:\n",
    "        f, Pxx = welch(window, fs=fs, nperseg=fs*2)\n",
    "        band_powers = {}\n",
    "        for band, (low, high) in bands.items():\n",
    "            band_power = np.trapz(Pxx[(f >= low) & (f <= high)], f[(f >= low) & (f <= high)])\n",
    "            band_powers[f'{band}_power'] = band_power\n",
    "        features.append(band_powers)\n",
    "\n",
    "    return pd.DataFrame(features)\n",
    "    \n",
    "\n",
    "def extract_frequency_domain_features_multichannel(data, fs=250):\n",
    "    \"\"\"\n",
    "    Extracts frequency domain features from multi-channel EEG signal data.\n",
    "    Parameters:\n",
    "    data (np.ndarray): A NumPy array with shape (channel, segment, 500), where each segment represents a 2-second window of the EEG signal.\n",
    "    fs (int): Sampling frequency of the EEG signal. Default is 250 Hz.\n",
    "    Returns:\n",
    "    dict: A dictionary containing the extracted frequency domain features with keys as {band}_power and values as numpy arrays of shape (channel, segment).\n",
    "    \"\"\"\n",
    "\n",
    "    # Define frequency bands\n",
    "    bands = {\n",
    "        'delta': (0.5, 4),\n",
    "        'theta': (4, 8),\n",
    "        'alpha': (8, 12),\n",
    "        'beta': (12, 30),\n",
    "        'gamma': (30, 40)\n",
    "    }\n",
    "\n",
    "    num_channels, num_segments, _ = data.shape\n",
    "    features = {f'{band}_power': np.zeros((num_channels, num_segments)) for band in bands}\n",
    "\n",
    "    for ch in range(num_channels):\n",
    "        for seg in range(num_segments):\n",
    "            window = data[ch, seg, :]\n",
    "            f, Pxx = welch(window, fs=fs, nperseg=fs*2)\n",
    "            for band, (low, high) in bands.items():\n",
    "                band_power = np.trapz(Pxx[(f >= low) & (f <= high)], f[(f >= low) & (f <= high)])\n",
    "                features[f'{band}_power'][ch, seg] = band_power\n",
    "\n",
    "    return features\n",
    "\n",
    "def extract_entropy_features(signal):\n",
    "    \"\"\"\n",
    "    Extracts entropy features from a 2D signal array.\n",
    "    Parameters:\n",
    "    signal (numpy.ndarray): A 2D array where each row represents a signal.\n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame containing the extracted entropy features:\n",
    "        - 'shannon_entropy': List of Shannon entropy values for each signal.\n",
    "        - 'sample_entropy': List of sample entropy values for each signal.\n",
    "        - 'spectral_entropy': List of spectral entropy values for each signal.\n",
    "    \"\"\"\n",
    "    \n",
    "    features = {\n",
    "        'shannon_entropy': [],\n",
    "        'sample_entropy': [],\n",
    "        'spectral_entropy': []\n",
    "    }\n",
    "    \n",
    "    # Iterate over the last dimension\n",
    "    for i in range(signal.shape[0]):\n",
    "        features['shannon_entropy'].append(ant.perm_entropy(signal[i, ...]))\n",
    "        features['sample_entropy'].append(ant.sample_entropy(signal[i, ...]))\n",
    "        features['spectral_entropy'].append(ant.spectral_entropy(signal[i, ...], sf=250, method='welch', normalize=True))\n",
    "    \n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "def extract_multichannel_entropy_features(signal):\n",
    "    \"\"\"\n",
    "    Extracts multichannel entropy features from a given EEG signal.\n",
    "    Parameters:\n",
    "    signal (numpy.ndarray): A 3D numpy array of shape (channels, windows, samples) representing the EEG signal.\n",
    "    Returns:\n",
    "    dict: A dictionary containing the following keys:\n",
    "        - 'shannon_entropy': A 2D numpy array of shape (channels, windows) with Shannon entropy values.\n",
    "        - 'sample_entropy': A 2D numpy array of shape (channels, windows) with Sample entropy values.\n",
    "        - 'spectral_entropy': A 2D numpy array of shape (channels, windows) with Spectral entropy values.\n",
    "    \"\"\"\n",
    "\n",
    "    channels, windows, _ = signal.shape\n",
    "    \n",
    "    features = {\n",
    "        'shannon_entropy': np.zeros((channels, windows)),\n",
    "        'sample_entropy': np.zeros((channels, windows)),\n",
    "        'spectral_entropy': np.zeros((channels, windows))\n",
    "    }\n",
    "    \n",
    "    for ch in range(channels):\n",
    "        for win in range(windows):\n",
    "            features['shannon_entropy'][ch, win] = ant.perm_entropy(signal[ch, win, :])\n",
    "            features['sample_entropy'][ch, win] = ant.sample_entropy(signal[ch, win, :])\n",
    "            features['spectral_entropy'][ch, win] = ant.spectral_entropy(signal[ch, win, :], sf=250, method='welch', normalize=True)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_wavelet_energy_features(signal, wavelet='db4', max_level=3):  # db4 commonly used for EEG signals\n",
    "    \"\"\"\n",
    "    Extracts wavelet energy features from a 2D numpy array signal.\n",
    "    Parameters:\n",
    "    signal (numpy.ndarray): A 2D numpy array where each row represents a signal segment.\n",
    "    wavelet (str): The type of wavelet to use for decomposition. Default is 'db4'.\n",
    "    max_level (int): The maximum level of wavelet decomposition. Default is 3.\n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame containing the wavelet energy features for each segment.\n",
    "                        Each column corresponds to the energy of a specific sub-band.\n",
    "    \"\"\"\n",
    "    \n",
    "    features = []\n",
    "\n",
    "    for segment in signal:\n",
    "        wp = pywt.WaveletPacket(data=segment, wavelet=wavelet, maxlevel=max_level)\n",
    "        feature_vector = []\n",
    "        for node in wp.get_level(max_level, 'freq'):\n",
    "            # Calculate energy of each node\n",
    "            energy = np.sum(np.square(node.data))\n",
    "            feature_vector.append(energy)\n",
    "        features.append(feature_vector)\n",
    "\n",
    "    # Name the features according to the sub-band\n",
    "    feature_names = [f'energy_band_{i}' for i in range(len(features[0]))]\n",
    "    df_features = pd.DataFrame(features, columns=feature_names)\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "def extract_wavelet_energy_features_multichannel(signal, wavelet='db4', max_level=3):\n",
    "    \"\"\"\n",
    "    Extracts wavelet energy features from a 3D numpy array signal.\n",
    "    Parameters:\n",
    "    signal (numpy.ndarray): A 3D numpy array with shape (channels, windows, 500).\n",
    "    wavelet (str): The type of wavelet to use for decomposition. Default is 'db4'.\n",
    "    max_level (int): The maximum level of wavelet decomposition. Default is 3.\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are feature names and values are numpy arrays of shape (channels, windows).\n",
    "    \"\"\"\n",
    "    \n",
    "    channels, windows, _ = signal.shape\n",
    "    features_dict = {}\n",
    "\n",
    "    for ch in range(channels):\n",
    "        channel_features = []\n",
    "        for win in range(windows):\n",
    "            segment = signal[ch, win, :]\n",
    "            wp = pywt.WaveletPacket(data=segment, wavelet=wavelet, maxlevel=max_level)\n",
    "            feature_vector = []\n",
    "            for node in wp.get_level(max_level, 'freq'):\n",
    "                # Calculate energy of each node\n",
    "                energy = np.sum(np.square(node.data))\n",
    "                feature_vector.append(energy)\n",
    "            channel_features.append(feature_vector)\n",
    "        \n",
    "        # Convert list of features to numpy array and store in dictionary\n",
    "        feature_names = [f'energy_band_{i}' for i in range(len(channel_features[0]))]\n",
    "        for i, feature_name in enumerate(feature_names):\n",
    "            if feature_name not in features_dict:\n",
    "                features_dict[feature_name] = np.zeros((channels, windows))\n",
    "            features_dict[feature_name][ch, :] = np.array([cf[i] for cf in channel_features])\n",
    "    \n",
    "    return features_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first load and reshape all the data\n",
    "all_data = []\n",
    "all_targets = []\n",
    "for (data,target) in training_data:\n",
    "    filtered_data =  butter_bandpass_filter(data,0.1,18,250,4)\n",
    "    reshaped_data = reshape_array_into_windows(filtered_data,250,2)\n",
    "    targets_flatten = target[..., :len(reshaped_data[0])].reshape(-1)\n",
    "    reshaped_data = reshaped_data.reshape((-1,reshaped_data.shape[-1]))\n",
    "    all_data.append(reshaped_data)\n",
    "    all_targets.append(targets_flatten)\n",
    "all_data = np.concatenate(all_data)\n",
    "all_targets = np.concatenate(all_targets)\n",
    "assert all_data.shape[0] == all_targets.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now compute the features over each 2 seconds segment\n",
    "\n",
    "time_features = extract_time_domain_features(all_data, return_type=\"dataframe\")\n",
    "frequency_features = extract_frequency_domain_features(all_data)\n",
    "entropy_features = extract_entropy_features(all_data)\n",
    "wavelet_energy_features = extract_wavelet_energy_features(all_data)\n",
    "\n",
    "# Combine the time, frequency, and entropy features into a single DataFrame\n",
    "features = pd.concat([time_features, frequency_features, entropy_features, wavelet_energy_features], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amplitude</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>stdev</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>hjorth_activity</th>\n",
       "      <th>hjorth_mobility</th>\n",
       "      <th>hjorth_complexity</th>\n",
       "      <th>...</th>\n",
       "      <th>sample_entropy</th>\n",
       "      <th>spectral_entropy</th>\n",
       "      <th>energy_band_0</th>\n",
       "      <th>energy_band_1</th>\n",
       "      <th>energy_band_2</th>\n",
       "      <th>energy_band_3</th>\n",
       "      <th>energy_band_4</th>\n",
       "      <th>energy_band_5</th>\n",
       "      <th>energy_band_6</th>\n",
       "      <th>energy_band_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28600.257975</td>\n",
       "      <td>1245.670285</td>\n",
       "      <td>21471.069232</td>\n",
       "      <td>-7129.188743</td>\n",
       "      <td>7780.162127</td>\n",
       "      <td>0.765047</td>\n",
       "      <td>-0.610001</td>\n",
       "      <td>6.053092e+07</td>\n",
       "      <td>0.043994</td>\n",
       "      <td>6.488830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004544</td>\n",
       "      <td>0.055527</td>\n",
       "      <td>3.131736e+10</td>\n",
       "      <td>2.026249e+08</td>\n",
       "      <td>2.364575e+06</td>\n",
       "      <td>273852.478188</td>\n",
       "      <td>7335.565786</td>\n",
       "      <td>10011.650727</td>\n",
       "      <td>17660.037549</td>\n",
       "      <td>11613.001761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7506.462109</td>\n",
       "      <td>-4965.798852</td>\n",
       "      <td>-476.438958</td>\n",
       "      <td>-7982.901067</td>\n",
       "      <td>2433.203314</td>\n",
       "      <td>0.304853</td>\n",
       "      <td>-1.311260</td>\n",
       "      <td>5.920478e+06</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>34.624977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012692</td>\n",
       "      <td>0.115011</td>\n",
       "      <td>1.725096e+10</td>\n",
       "      <td>2.053229e+04</td>\n",
       "      <td>1.374747e+03</td>\n",
       "      <td>1052.824111</td>\n",
       "      <td>176.143959</td>\n",
       "      <td>67.214865</td>\n",
       "      <td>3.894931</td>\n",
       "      <td>3.055691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4054.175414</td>\n",
       "      <td>2364.739039</td>\n",
       "      <td>3590.077431</td>\n",
       "      <td>-464.097984</td>\n",
       "      <td>1187.694358</td>\n",
       "      <td>-0.797484</td>\n",
       "      <td>-0.582127</td>\n",
       "      <td>1.410618e+06</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>50.729171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.075448</td>\n",
       "      <td>3.576688e+09</td>\n",
       "      <td>1.574383e+04</td>\n",
       "      <td>8.890063e+02</td>\n",
       "      <td>812.854860</td>\n",
       "      <td>145.044263</td>\n",
       "      <td>43.013947</td>\n",
       "      <td>2.302323</td>\n",
       "      <td>1.947904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2187.981464</td>\n",
       "      <td>2755.580822</td>\n",
       "      <td>3620.974382</td>\n",
       "      <td>1432.992918</td>\n",
       "      <td>695.837658</td>\n",
       "      <td>-0.312038</td>\n",
       "      <td>-1.245956</td>\n",
       "      <td>4.841900e+05</td>\n",
       "      <td>0.006904</td>\n",
       "      <td>59.065314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>0.136786</td>\n",
       "      <td>4.525491e+09</td>\n",
       "      <td>6.757636e+03</td>\n",
       "      <td>3.849655e+02</td>\n",
       "      <td>667.420601</td>\n",
       "      <td>125.166160</td>\n",
       "      <td>32.429763</td>\n",
       "      <td>1.707716</td>\n",
       "      <td>1.597904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2362.447080</td>\n",
       "      <td>8.122686</td>\n",
       "      <td>1420.377480</td>\n",
       "      <td>-942.069600</td>\n",
       "      <td>649.347508</td>\n",
       "      <td>0.350397</td>\n",
       "      <td>-0.977942</td>\n",
       "      <td>4.216522e+05</td>\n",
       "      <td>0.006834</td>\n",
       "      <td>68.005797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017123</td>\n",
       "      <td>0.088179</td>\n",
       "      <td>2.903698e+08</td>\n",
       "      <td>1.694703e+04</td>\n",
       "      <td>8.184609e+02</td>\n",
       "      <td>814.471830</td>\n",
       "      <td>120.684325</td>\n",
       "      <td>28.069911</td>\n",
       "      <td>2.113378</td>\n",
       "      <td>2.217117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      amplitude         mean           max          min        stdev  \\\n",
       "0  28600.257975  1245.670285  21471.069232 -7129.188743  7780.162127   \n",
       "1   7506.462109 -4965.798852   -476.438958 -7982.901067  2433.203314   \n",
       "2   4054.175414  2364.739039   3590.077431  -464.097984  1187.694358   \n",
       "3   2187.981464  2755.580822   3620.974382  1432.992918   695.837658   \n",
       "4   2362.447080     8.122686   1420.377480  -942.069600   649.347508   \n",
       "\n",
       "   skewness  kurtosis  hjorth_activity  hjorth_mobility  hjorth_complexity  \\\n",
       "0  0.765047 -0.610001     6.053092e+07         0.043994           6.488830   \n",
       "1  0.304853 -1.311260     5.920478e+06         0.005689          34.624977   \n",
       "2 -0.797484 -0.582127     1.410618e+06         0.005910          50.729171   \n",
       "3 -0.312038 -1.245956     4.841900e+05         0.006904          59.065314   \n",
       "4  0.350397 -0.977942     4.216522e+05         0.006834          68.005797   \n",
       "\n",
       "   ...  sample_entropy  spectral_entropy  energy_band_0  energy_band_1  \\\n",
       "0  ...        0.004544          0.055527   3.131736e+10   2.026249e+08   \n",
       "1  ...        0.012692          0.115011   1.725096e+10   2.053229e+04   \n",
       "2  ...        0.002690          0.075448   3.576688e+09   1.574383e+04   \n",
       "3  ...        0.015968          0.136786   4.525491e+09   6.757636e+03   \n",
       "4  ...        0.017123          0.088179   2.903698e+08   1.694703e+04   \n",
       "\n",
       "   energy_band_2  energy_band_3  energy_band_4  energy_band_5  energy_band_6  \\\n",
       "0   2.364575e+06  273852.478188    7335.565786   10011.650727   17660.037549   \n",
       "1   1.374747e+03    1052.824111     176.143959      67.214865       3.894931   \n",
       "2   8.890063e+02     812.854860     145.044263      43.013947       2.302323   \n",
       "3   3.849655e+02     667.420601     125.166160      32.429763       1.707716   \n",
       "4   8.184609e+02     814.471830     120.684325      28.069911       2.113378   \n",
       "\n",
       "   energy_band_7  \n",
       "0   11613.001761  \n",
       "1       3.055691  \n",
       "2       1.947904  \n",
       "3       1.597904  \n",
       "4       2.217117  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.to_csv(\"features.csv\")\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amplitude</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>stdev</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>hjorth_activity</th>\n",
       "      <th>hjorth_mobility</th>\n",
       "      <th>hjorth_complexity</th>\n",
       "      <th>...</th>\n",
       "      <th>sample_entropy</th>\n",
       "      <th>spectral_entropy</th>\n",
       "      <th>energy_band_0</th>\n",
       "      <th>energy_band_1</th>\n",
       "      <th>energy_band_2</th>\n",
       "      <th>energy_band_3</th>\n",
       "      <th>energy_band_4</th>\n",
       "      <th>energy_band_5</th>\n",
       "      <th>energy_band_6</th>\n",
       "      <th>energy_band_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28600.26</td>\n",
       "      <td>1245.67</td>\n",
       "      <td>21471.07</td>\n",
       "      <td>-7129.19</td>\n",
       "      <td>7780.16</td>\n",
       "      <td>0.77</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>60530922.73</td>\n",
       "      <td>0.04</td>\n",
       "      <td>6.49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>31317359394.08</td>\n",
       "      <td>202624914.52</td>\n",
       "      <td>2364574.84</td>\n",
       "      <td>273852.48</td>\n",
       "      <td>7335.57</td>\n",
       "      <td>10011.65</td>\n",
       "      <td>17660.04</td>\n",
       "      <td>11613.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7506.46</td>\n",
       "      <td>-4965.80</td>\n",
       "      <td>-476.44</td>\n",
       "      <td>-7982.90</td>\n",
       "      <td>2433.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>5920478.37</td>\n",
       "      <td>0.01</td>\n",
       "      <td>34.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.12</td>\n",
       "      <td>17250962984.42</td>\n",
       "      <td>20532.29</td>\n",
       "      <td>1374.75</td>\n",
       "      <td>1052.82</td>\n",
       "      <td>176.14</td>\n",
       "      <td>67.21</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4054.18</td>\n",
       "      <td>2364.74</td>\n",
       "      <td>3590.08</td>\n",
       "      <td>-464.10</td>\n",
       "      <td>1187.69</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>1410617.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50.73</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3576687818.39</td>\n",
       "      <td>15743.83</td>\n",
       "      <td>889.01</td>\n",
       "      <td>812.85</td>\n",
       "      <td>145.04</td>\n",
       "      <td>43.01</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2187.98</td>\n",
       "      <td>2755.58</td>\n",
       "      <td>3620.97</td>\n",
       "      <td>1432.99</td>\n",
       "      <td>695.84</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>484190.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>59.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.14</td>\n",
       "      <td>4525490622.25</td>\n",
       "      <td>6757.64</td>\n",
       "      <td>384.97</td>\n",
       "      <td>667.42</td>\n",
       "      <td>125.17</td>\n",
       "      <td>32.43</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2362.45</td>\n",
       "      <td>8.12</td>\n",
       "      <td>1420.38</td>\n",
       "      <td>-942.07</td>\n",
       "      <td>649.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>421652.19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>68.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.09</td>\n",
       "      <td>290369777.33</td>\n",
       "      <td>16947.03</td>\n",
       "      <td>818.46</td>\n",
       "      <td>814.47</td>\n",
       "      <td>120.68</td>\n",
       "      <td>28.07</td>\n",
       "      <td>2.11</td>\n",
       "      <td>2.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   amplitude     mean      max      min   stdev  skewness  kurtosis  \\\n",
       "0   28600.26  1245.67 21471.07 -7129.19 7780.16      0.77     -0.61   \n",
       "1    7506.46 -4965.80  -476.44 -7982.90 2433.20      0.30     -1.31   \n",
       "2    4054.18  2364.74  3590.08  -464.10 1187.69     -0.80     -0.58   \n",
       "3    2187.98  2755.58  3620.97  1432.99  695.84     -0.31     -1.25   \n",
       "4    2362.45     8.12  1420.38  -942.07  649.35      0.35     -0.98   \n",
       "\n",
       "   hjorth_activity  hjorth_mobility  hjorth_complexity  ...  sample_entropy  \\\n",
       "0      60530922.73             0.04               6.49  ...            0.00   \n",
       "1       5920478.37             0.01              34.62  ...            0.01   \n",
       "2       1410617.89             0.01              50.73  ...            0.00   \n",
       "3        484190.05             0.01              59.07  ...            0.02   \n",
       "4        421652.19             0.01              68.01  ...            0.02   \n",
       "\n",
       "   spectral_entropy  energy_band_0  energy_band_1  energy_band_2  \\\n",
       "0              0.06 31317359394.08   202624914.52     2364574.84   \n",
       "1              0.12 17250962984.42       20532.29        1374.75   \n",
       "2              0.08  3576687818.39       15743.83         889.01   \n",
       "3              0.14  4525490622.25        6757.64         384.97   \n",
       "4              0.09   290369777.33       16947.03         818.46   \n",
       "\n",
       "   energy_band_3  energy_band_4  energy_band_5  energy_band_6  energy_band_7  \n",
       "0      273852.48        7335.57       10011.65       17660.04       11613.00  \n",
       "1        1052.82         176.14          67.21           3.89           3.06  \n",
       "2         812.85         145.04          43.01           2.30           1.95  \n",
       "3         667.42         125.17          32.43           1.71           1.60  \n",
       "4         814.47         120.68          28.07           2.11           2.22  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv(\"features.csv\", index_col=0)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed features: ['max', 'min', 'stdev', 'hjorth_activity', 'delta_power', 'alpha_power', 'beta_power', 'gamma_power', 'sample_entropy', 'spectral_entropy', 'energy_band_0', 'energy_band_1', 'energy_band_2', 'energy_band_3', 'energy_band_5', 'energy_band_6', 'energy_band_7']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amplitude</th>\n",
       "      <th>mean</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>hjorth_mobility</th>\n",
       "      <th>hjorth_complexity</th>\n",
       "      <th>theta_power</th>\n",
       "      <th>shannon_entropy</th>\n",
       "      <th>energy_band_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28600.26</td>\n",
       "      <td>1245.67</td>\n",
       "      <td>0.77</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>0.04</td>\n",
       "      <td>6.49</td>\n",
       "      <td>422.10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>7335.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7506.46</td>\n",
       "      <td>-4965.80</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>0.01</td>\n",
       "      <td>34.62</td>\n",
       "      <td>529.88</td>\n",
       "      <td>0.75</td>\n",
       "      <td>176.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4054.18</td>\n",
       "      <td>2364.74</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50.73</td>\n",
       "      <td>155.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>145.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2187.98</td>\n",
       "      <td>2755.58</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>59.07</td>\n",
       "      <td>362.70</td>\n",
       "      <td>1.11</td>\n",
       "      <td>125.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2362.45</td>\n",
       "      <td>8.12</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>68.01</td>\n",
       "      <td>100.72</td>\n",
       "      <td>1.02</td>\n",
       "      <td>120.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amplitude     mean  skewness  kurtosis  hjorth_mobility  hjorth_complexity  \\\n",
       "0   28600.26  1245.67      0.77     -0.61             0.04               6.49   \n",
       "1    7506.46 -4965.80      0.30     -1.31             0.01              34.62   \n",
       "2    4054.18  2364.74     -0.80     -0.58             0.01              50.73   \n",
       "3    2187.98  2755.58     -0.31     -1.25             0.01              59.07   \n",
       "4    2362.45     8.12      0.35     -0.98             0.01              68.01   \n",
       "\n",
       "   theta_power  shannon_entropy  energy_band_4  \n",
       "0       422.10             0.30        7335.57  \n",
       "1       529.88             0.75         176.14  \n",
       "2       155.72             0.75         145.04  \n",
       "3       362.70             1.11         125.17  \n",
       "4       100.72             1.02         120.68  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from features.utils import remove_collinear_features\n",
    "\n",
    "# Remove collinear features\n",
    "features = remove_collinear_features(features, threshold=0.6)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_train = 0.7\n",
    "n_train = int(prop_train * len(features))\n",
    "\n",
    "x_train = features[:n_train]\n",
    "y_train = all_targets[:n_train]\n",
    "\n",
    "x_val = features[n_train:]\n",
    "y_val = all_targets[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "\n",
    "selectKBest = SelectKBest(f_classif, k=20)\n",
    "\n",
    "x_train_sel = selectKBest.fit_transform(x_train, y_train)\n",
    "x_val_sel = selectKBest.transform(x_val)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'tuple' object has no attribute '__name__'\n",
      "Invalid Classifier(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 21/22 [00:06<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 77195, number of negative: 2805\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.964938 -> initscore=3.314931\n",
      "[LightGBM] [Info] Start training from score 3.314931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:07<00:00,  2.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       " Model                                                                           \n",
       " LGBMClassifier                     0.83               0.82     0.82      0.83   \n",
       " XGBClassifier                      0.78               0.80     0.80      0.78   \n",
       " QuadraticDiscriminantAnalysis      0.80               0.79     0.79      0.80   \n",
       " ExtraTreeClassifier                0.80               0.79     0.79      0.80   \n",
       " GaussianNB                         0.77               0.78     0.78      0.78   \n",
       " DecisionTreeClassifier             0.72               0.77     0.77      0.73   \n",
       " Perceptron                         0.58               0.68     0.68      0.56   \n",
       " CalibratedClassifierCV             0.47               0.59     0.59      0.41   \n",
       " PassiveAggressiveClassifier        0.47               0.59     0.59      0.42   \n",
       " SGDClassifier                      0.44               0.57     0.57      0.36   \n",
       " LinearSVC                          0.42               0.56     0.56      0.32   \n",
       " LogisticRegression                 0.41               0.54     0.54      0.29   \n",
       " NearestCentroid                    0.39               0.52     0.52      0.28   \n",
       " LinearDiscriminantAnalysis         0.37               0.52     0.52      0.23   \n",
       " RidgeClassifier                    0.35               0.50     0.50      0.19   \n",
       " RidgeClassifierCV                  0.35               0.50     0.50      0.19   \n",
       " DummyClassifier                    0.35               0.50     0.50      0.18   \n",
       " \n",
       "                                Time Taken  \n",
       " Model                                      \n",
       " LGBMClassifier                       0.81  \n",
       " XGBClassifier                        0.71  \n",
       " QuadraticDiscriminantAnalysis        0.14  \n",
       " ExtraTreeClassifier                  0.14  \n",
       " GaussianNB                           0.11  \n",
       " DecisionTreeClassifier               1.95  \n",
       " Perceptron                           0.29  \n",
       " CalibratedClassifierCV               1.44  \n",
       " PassiveAggressiveClassifier          0.26  \n",
       " SGDClassifier                        0.22  \n",
       " LinearSVC                            0.38  \n",
       " LogisticRegression                   0.30  \n",
       " NearestCentroid                      0.11  \n",
       " LinearDiscriminantAnalysis           0.21  \n",
       " RidgeClassifier                      0.13  \n",
       " RidgeClassifierCV                    0.16  \n",
       " DummyClassifier                      0.09  ,\n",
       "                                Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       " Model                                                                           \n",
       " LGBMClassifier                     0.83               0.82     0.82      0.83   \n",
       " XGBClassifier                      0.78               0.80     0.80      0.78   \n",
       " QuadraticDiscriminantAnalysis      0.80               0.79     0.79      0.80   \n",
       " ExtraTreeClassifier                0.80               0.79     0.79      0.80   \n",
       " GaussianNB                         0.77               0.78     0.78      0.78   \n",
       " DecisionTreeClassifier             0.72               0.77     0.77      0.73   \n",
       " Perceptron                         0.58               0.68     0.68      0.56   \n",
       " CalibratedClassifierCV             0.47               0.59     0.59      0.41   \n",
       " PassiveAggressiveClassifier        0.47               0.59     0.59      0.42   \n",
       " SGDClassifier                      0.44               0.57     0.57      0.36   \n",
       " LinearSVC                          0.42               0.56     0.56      0.32   \n",
       " LogisticRegression                 0.41               0.54     0.54      0.29   \n",
       " NearestCentroid                    0.39               0.52     0.52      0.28   \n",
       " LinearDiscriminantAnalysis         0.37               0.52     0.52      0.23   \n",
       " RidgeClassifier                    0.35               0.50     0.50      0.19   \n",
       " RidgeClassifierCV                  0.35               0.50     0.50      0.19   \n",
       " DummyClassifier                    0.35               0.50     0.50      0.18   \n",
       " \n",
       "                                Time Taken  \n",
       " Model                                      \n",
       " LGBMClassifier                       0.81  \n",
       " XGBClassifier                        0.71  \n",
       " QuadraticDiscriminantAnalysis        0.14  \n",
       " ExtraTreeClassifier                  0.14  \n",
       " GaussianNB                           0.11  \n",
       " DecisionTreeClassifier               1.95  \n",
       " Perceptron                           0.29  \n",
       " CalibratedClassifierCV               1.44  \n",
       " PassiveAggressiveClassifier          0.26  \n",
       " SGDClassifier                        0.22  \n",
       " LinearSVC                            0.38  \n",
       " LogisticRegression                   0.30  \n",
       " NearestCentroid                      0.11  \n",
       " LinearDiscriminantAnalysis           0.21  \n",
       " RidgeClassifier                      0.13  \n",
       " RidgeClassifierCV                    0.16  \n",
       " DummyClassifier                      0.09  )"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highmem_classifiers = [\"LabelSpreading\", \"LabelPropagation\", \"BernoulliNB\", \"KNeighborsClassifier\", \"ElasticNetClassifier\", \"GradientBoostingClassifier\", \"HistGradientBoostingClassifier\", \"BaggingClassifier\", \"RandomForestClassifier\", \"SVC\", \"ExtraTreesClassifier\", \"AdaBoostClassifier\", \"KNeighborsClassifier\"]\n",
    "\n",
    "# Remove the high memory classifiers from the list\n",
    "classifiers = [c for c in CLASSIFIERS if c[0] not in highmem_classifiers]\n",
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None, classifiers=classifiers)\n",
    "models = clf.fit(x_train[:80000], x_val[:50000], y_train[:80000], y_val[:50000])  # Only use a subset of the data for faster computation\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
