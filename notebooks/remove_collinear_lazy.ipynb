{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define a base directory for the dataset\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    # Code is running in Google Colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    base_dir = Path('/content/drive/My Drive/Supervised-Project/Data')\n",
    "    !pip install numpy seaborn matplotlib scipy pandas ts2vg scikit-image pyfeats scikit-learn==1.2.0 lazypredict dask[dataframe] antropy pywt\n",
    "else:\n",
    "    # Code is running locally\n",
    "    base_dir = Path('Data/')  # Adjust to your local relative path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's load the training data\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter\n",
    "import pandas as pd\n",
    "from features.wavelet_decomposition import extract_wavelet_energy_features\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import welch\n",
    "import antropy as ant\n",
    "import pywt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = Path(\"../data/train/\")\n",
    "training_data = [(np.load(ROOT_PATH / f\"data_{i}.npy\"),np.load(ROOT_PATH / f\"target_{i}.npy\")) for i in range(4)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    return butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def reshape_array_into_windows(x, sample_rate, window_duration_in_seconds):\n",
    "    \"\"\"\n",
    "    Reshape the data into an array of shape (C, T, window) where 'window' contains\n",
    "    the points corresponding to 'window_duration' seconds of data.\n",
    "\n",
    "    Parameters:\n",
    "    x (numpy array): The input data array.\n",
    "    sample_rate (int): The number of samples per second.\n",
    "    window_duration_in_seconds (float): The duration of each window in seconds.\n",
    "\n",
    "    Returns:\n",
    "    reshaped_x (numpy array): The reshaped array with shape (C, T, window).\n",
    "    \"\"\"\n",
    "    # Calculate the number of samples in one window\n",
    "    window_size = int(window_duration_in_seconds * sample_rate)\n",
    "    \n",
    "    # Ensure the total length of x is a multiple of window_size\n",
    "    total_samples = x.shape[-1]\n",
    "    if total_samples % window_size != 0:\n",
    "        # Truncate or pad x to make it divisible by window_size\n",
    "        x = x[..., :total_samples - (total_samples % window_size)]\n",
    "    # Reshape x into (C, T, window)\n",
    "    reshaped_x = x.reshape(x.shape[0], -1, window_size)\n",
    "\n",
    "    return reshaped_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time domain features\n",
    "def extract_time_domain_features(data, return_type='dataframe'):\n",
    "    \"\"\"\n",
    "    Extracts time-domain features from EEG data.\n",
    "    Parameters:\n",
    "    data (numpy.ndarray): A 2D or 3D array where each row (or each slice in the case of 3D) represents a 2-second window of EEG data sampled at 250 Hz (i.e., each row has 500 data points).\n",
    "    return_type (str): The type of the return value, either 'dataframe' or 'numpy'.\n",
    "    Returns:\n",
    "    pandas.DataFrame or numpy.ndarray: A DataFrame or ndarray containing the following time-domain features for each row (or slice) of the input data:\n",
    "        - amplitude: The difference between the maximum and minimum values.\n",
    "        - mean: The mean value.\n",
    "        - max: The maximum value.\n",
    "        - min: The minimum value.\n",
    "        - stdev: The standard deviation.\n",
    "        - skewness: The skewness of the data.\n",
    "        - kurtosis: The kurtosis of the data.\n",
    "        - hjorth_activity: The Hjorth activity parameter.\n",
    "        - hjorth_mobility: The Hjorth mobility parameter.\n",
    "        - hjorth_complexity: The Hjorth complexity parameter.\n",
    "    \"\"\"\n",
    "\n",
    "    is_3d = data.ndim == 3\n",
    "\n",
    "    amplitude = np.max(data, axis=-1) - np.min(data, axis=-1)\n",
    "    mean_values = np.mean(data, axis=-1)\n",
    "    max_values = np.max(data, axis=-1)\n",
    "    min_values = np.min(data, axis=-1)\n",
    "    stdev_values = np.std(data, axis=-1)\n",
    "    skewness_values = skew(data, axis=-1)\n",
    "    kurtosis_values = kurtosis(data, axis=-1)\n",
    "\n",
    "    # Hjorth parameters\n",
    "    def hjorth_parameters(data):\n",
    "        first_deriv = np.diff(data, axis=-1)\n",
    "        second_deriv = np.diff(first_deriv, axis=-1)\n",
    "        var_zero = np.var(data, axis=-1)\n",
    "        var_d1 = np.var(first_deriv, axis=-1)\n",
    "        var_d2 = np.var(second_deriv, axis=-1)\n",
    "        activity = var_zero\n",
    "        mobility = np.sqrt(var_d1 / var_zero)\n",
    "        complexity = np.sqrt(var_d2 / var_d1) / mobility\n",
    "        return activity, mobility, complexity\n",
    "\n",
    "    hjorth_activity, hjorth_mobility, hjorth_complexity = hjorth_parameters(data)\n",
    "\n",
    "    features = {\n",
    "        \"amplitude\": amplitude,\n",
    "        \"mean\": mean_values,\n",
    "        \"max\": max_values,\n",
    "        \"min\": min_values,\n",
    "        \"stdev\": stdev_values,\n",
    "        \"skewness\": skewness_values,\n",
    "        \"kurtosis\": kurtosis_values,\n",
    "        \"hjorth_activity\": hjorth_activity,\n",
    "        \"hjorth_mobility\": hjorth_mobility,\n",
    "        \"hjorth_complexity\": hjorth_complexity,\n",
    "    }\n",
    "\n",
    "    if not is_3d:\n",
    "        for key in features:\n",
    "            features[key] = features[key].reshape(-1)\n",
    "\n",
    "    if return_type == 'dataframe':\n",
    "        return pd.DataFrame(features)\n",
    "    elif return_type == 'numpy':\n",
    "        return features\n",
    "    else:\n",
    "       raise ValueError(\"return_type must be either 'dataframe' or 'numpy'\")\n",
    "    \n",
    "\n",
    "# Extract frequency domain features\n",
    "def extract_frequency_domain_features(data, fs=250):\n",
    "    \"\"\"\n",
    "    Extracts frequency domain features from EEG signal data.\n",
    "    Parameters:\n",
    "    data (np.ndarray): A NumPy array where each row represents a 2-second window of the EEG signal, \n",
    "                       with each row containing 500 data points.\n",
    "    fs (int): Sampling frequency of the EEG signal. Default is 250 Hz.\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the extracted frequency domain features.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define frequency bands\n",
    "    bands = {\n",
    "        'delta': (0.5, 4),\n",
    "        'theta': (4, 8),\n",
    "        'alpha': (8, 12),\n",
    "        'beta': (12, 30),\n",
    "        'gamma': (30, 40)\n",
    "    }\n",
    "\n",
    "    features = []\n",
    "\n",
    "    for window in data:\n",
    "        f, Pxx = welch(window, fs=fs, nperseg=fs*2)\n",
    "        band_powers = {}\n",
    "        for band, (low, high) in bands.items():\n",
    "            band_power = np.trapz(Pxx[(f >= low) & (f <= high)], f[(f >= low) & (f <= high)])\n",
    "            band_powers[f'{band}_power'] = band_power\n",
    "        features.append(band_powers)\n",
    "\n",
    "    return pd.DataFrame(features)\n",
    "    \n",
    "\n",
    "def extract_frequency_domain_features_multichannel(data, fs=250):\n",
    "    \"\"\"\n",
    "    Extracts frequency domain features from multi-channel EEG signal data.\n",
    "    Parameters:\n",
    "    data (np.ndarray): A NumPy array with shape (channel, segment, 500), where each segment represents a 2-second window of the EEG signal.\n",
    "    fs (int): Sampling frequency of the EEG signal. Default is 250 Hz.\n",
    "    Returns:\n",
    "    dict: A dictionary containing the extracted frequency domain features with keys as {band}_power and values as numpy arrays of shape (channel, segment).\n",
    "    \"\"\"\n",
    "\n",
    "    # Define frequency bands\n",
    "    bands = {\n",
    "        'delta': (0.5, 4),\n",
    "        'theta': (4, 8),\n",
    "        'alpha': (8, 12),\n",
    "        'beta': (12, 30),\n",
    "        'gamma': (30, 40)\n",
    "    }\n",
    "\n",
    "    num_channels, num_segments, _ = data.shape\n",
    "    features = {f'{band}_power': np.zeros((num_channels, num_segments)) for band in bands}\n",
    "\n",
    "    for ch in range(num_channels):\n",
    "        for seg in range(num_segments):\n",
    "            window = data[ch, seg, :]\n",
    "            f, Pxx = welch(window, fs=fs, nperseg=fs*2)\n",
    "            for band, (low, high) in bands.items():\n",
    "                band_power = np.trapz(Pxx[(f >= low) & (f <= high)], f[(f >= low) & (f <= high)])\n",
    "                features[f'{band}_power'][ch, seg] = band_power\n",
    "\n",
    "    return features\n",
    "\n",
    "def extract_entropy_features(signal):\n",
    "    \"\"\"\n",
    "    Extracts entropy features from a 2D signal array.\n",
    "    Parameters:\n",
    "    signal (numpy.ndarray): A 2D array where each row represents a signal.\n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame containing the extracted entropy features:\n",
    "        - 'shannon_entropy': List of Shannon entropy values for each signal.\n",
    "        - 'sample_entropy': List of sample entropy values for each signal.\n",
    "        - 'spectral_entropy': List of spectral entropy values for each signal.\n",
    "    \"\"\"\n",
    "    \n",
    "    features = {\n",
    "        'shannon_entropy': [],\n",
    "        'sample_entropy': [],\n",
    "        'spectral_entropy': []\n",
    "    }\n",
    "    \n",
    "    # Iterate over the last dimension\n",
    "    for i in range(signal.shape[0]):\n",
    "        features['shannon_entropy'].append(ant.perm_entropy(signal[i, ...]))\n",
    "        features['sample_entropy'].append(ant.sample_entropy(signal[i, ...]))\n",
    "        features['spectral_entropy'].append(ant.spectral_entropy(signal[i, ...], sf=250, method='welch', normalize=True))\n",
    "    \n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "def extract_multichannel_entropy_features(signal):\n",
    "    \"\"\"\n",
    "    Extracts multichannel entropy features from a given EEG signal.\n",
    "    Parameters:\n",
    "    signal (numpy.ndarray): A 3D numpy array of shape (channels, windows, samples) representing the EEG signal.\n",
    "    Returns:\n",
    "    dict: A dictionary containing the following keys:\n",
    "        - 'shannon_entropy': A 2D numpy array of shape (channels, windows) with Shannon entropy values.\n",
    "        - 'sample_entropy': A 2D numpy array of shape (channels, windows) with Sample entropy values.\n",
    "        - 'spectral_entropy': A 2D numpy array of shape (channels, windows) with Spectral entropy values.\n",
    "    \"\"\"\n",
    "\n",
    "    channels, windows, _ = signal.shape\n",
    "    \n",
    "    features = {\n",
    "        'shannon_entropy': np.zeros((channels, windows)),\n",
    "        'sample_entropy': np.zeros((channels, windows)),\n",
    "        'spectral_entropy': np.zeros((channels, windows))\n",
    "    }\n",
    "    \n",
    "    for ch in range(channels):\n",
    "        for win in range(windows):\n",
    "            features['shannon_entropy'][ch, win] = ant.perm_entropy(signal[ch, win, :])\n",
    "            features['sample_entropy'][ch, win] = ant.sample_entropy(signal[ch, win, :])\n",
    "            features['spectral_entropy'][ch, win] = ant.spectral_entropy(signal[ch, win, :], sf=250, method='welch', normalize=True)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_wavelet_energy_features(signal, wavelet='db4', max_level=3):  # db4 commonly used for EEG signals\n",
    "    \"\"\"\n",
    "    Extracts wavelet energy features from a 2D numpy array signal.\n",
    "    Parameters:\n",
    "    signal (numpy.ndarray): A 2D numpy array where each row represents a signal segment.\n",
    "    wavelet (str): The type of wavelet to use for decomposition. Default is 'db4'.\n",
    "    max_level (int): The maximum level of wavelet decomposition. Default is 3.\n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame containing the wavelet energy features for each segment.\n",
    "                        Each column corresponds to the energy of a specific sub-band.\n",
    "    \"\"\"\n",
    "    \n",
    "    features = []\n",
    "\n",
    "    for segment in signal:\n",
    "        wp = pywt.WaveletPacket(data=segment, wavelet=wavelet, maxlevel=max_level)\n",
    "        feature_vector = []\n",
    "        for node in wp.get_level(max_level, 'freq'):\n",
    "            # Calculate energy of each node\n",
    "            energy = np.sum(np.square(node.data))\n",
    "            feature_vector.append(energy)\n",
    "        features.append(feature_vector)\n",
    "\n",
    "    # Name the features according to the sub-band\n",
    "    feature_names = [f'energy_band_{i}' for i in range(len(features[0]))]\n",
    "    df_features = pd.DataFrame(features, columns=feature_names)\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "def extract_wavelet_energy_features_multichannel(signal, wavelet='db4', max_level=3):\n",
    "    \"\"\"\n",
    "    Extracts wavelet energy features from a 3D numpy array signal.\n",
    "    Parameters:\n",
    "    signal (numpy.ndarray): A 3D numpy array with shape (channels, windows, 500).\n",
    "    wavelet (str): The type of wavelet to use for decomposition. Default is 'db4'.\n",
    "    max_level (int): The maximum level of wavelet decomposition. Default is 3.\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are feature names and values are numpy arrays of shape (channels, windows).\n",
    "    \"\"\"\n",
    "    \n",
    "    channels, windows, _ = signal.shape\n",
    "    features_dict = {}\n",
    "\n",
    "    for ch in range(channels):\n",
    "        channel_features = []\n",
    "        for win in range(windows):\n",
    "            segment = signal[ch, win, :]\n",
    "            wp = pywt.WaveletPacket(data=segment, wavelet=wavelet, maxlevel=max_level)\n",
    "            feature_vector = []\n",
    "            for node in wp.get_level(max_level, 'freq'):\n",
    "                # Calculate energy of each node\n",
    "                energy = np.sum(np.square(node.data))\n",
    "                feature_vector.append(energy)\n",
    "            channel_features.append(feature_vector)\n",
    "        \n",
    "        # Convert list of features to numpy array and store in dictionary\n",
    "        feature_names = [f'energy_band_{i}' for i in range(len(channel_features[0]))]\n",
    "        for i, feature_name in enumerate(feature_names):\n",
    "            if feature_name not in features_dict:\n",
    "                features_dict[feature_name] = np.zeros((channels, windows))\n",
    "            features_dict[feature_name][ch, :] = np.array([cf[i] for cf in channel_features])\n",
    "    \n",
    "    return features_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first load and reshape all the data\n",
    "all_data = []\n",
    "all_targets = []\n",
    "for (data,target) in training_data:\n",
    "    filtered_data =  butter_bandpass_filter(data,0.1,18,250,4)\n",
    "    reshaped_data = reshape_array_into_windows(filtered_data,250,2)\n",
    "    targets_flatten = target[..., :len(reshaped_data[0])].reshape(-1)\n",
    "    reshaped_data = reshaped_data.reshape((-1,reshaped_data.shape[-1]))\n",
    "    all_data.append(reshaped_data)\n",
    "    all_targets.append(targets_flatten)\n",
    "all_data = np.concatenate(all_data)\n",
    "all_targets = np.concatenate(all_targets)\n",
    "assert all_data.shape[0] == all_targets.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now compute the features over each 2 seconds segment\n",
    "\n",
    "time_features = extract_time_domain_features(all_data, return_type=\"dataframe\")\n",
    "frequency_features = extract_frequency_domain_features(all_data)\n",
    "entropy_features = extract_entropy_features(all_data)\n",
    "wavelet_energy_features = extract_wavelet_energy_features(all_data)\n",
    "\n",
    "# Combine the time, frequency, and entropy features into a single DataFrame\n",
    "features = pd.concat([time_features, frequency_features, entropy_features, wavelet_energy_features], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amplitude</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>stdev</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>hjorth_activity</th>\n",
       "      <th>hjorth_mobility</th>\n",
       "      <th>hjorth_complexity</th>\n",
       "      <th>...</th>\n",
       "      <th>sample_entropy</th>\n",
       "      <th>spectral_entropy</th>\n",
       "      <th>energy_band_0</th>\n",
       "      <th>energy_band_1</th>\n",
       "      <th>energy_band_2</th>\n",
       "      <th>energy_band_3</th>\n",
       "      <th>energy_band_4</th>\n",
       "      <th>energy_band_5</th>\n",
       "      <th>energy_band_6</th>\n",
       "      <th>energy_band_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28600.257975</td>\n",
       "      <td>1245.670285</td>\n",
       "      <td>21471.069232</td>\n",
       "      <td>-7129.188743</td>\n",
       "      <td>7780.162127</td>\n",
       "      <td>0.765047</td>\n",
       "      <td>-0.610001</td>\n",
       "      <td>6.053092e+07</td>\n",
       "      <td>0.043994</td>\n",
       "      <td>6.488830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004544</td>\n",
       "      <td>0.055527</td>\n",
       "      <td>3.131736e+10</td>\n",
       "      <td>2.026249e+08</td>\n",
       "      <td>2.364575e+06</td>\n",
       "      <td>273852.478188</td>\n",
       "      <td>7335.565786</td>\n",
       "      <td>10011.650727</td>\n",
       "      <td>17660.037549</td>\n",
       "      <td>11613.001761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7506.462109</td>\n",
       "      <td>-4965.798852</td>\n",
       "      <td>-476.438958</td>\n",
       "      <td>-7982.901067</td>\n",
       "      <td>2433.203314</td>\n",
       "      <td>0.304853</td>\n",
       "      <td>-1.311260</td>\n",
       "      <td>5.920478e+06</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>34.624977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012692</td>\n",
       "      <td>0.115011</td>\n",
       "      <td>1.725096e+10</td>\n",
       "      <td>2.053229e+04</td>\n",
       "      <td>1.374747e+03</td>\n",
       "      <td>1052.824111</td>\n",
       "      <td>176.143959</td>\n",
       "      <td>67.214865</td>\n",
       "      <td>3.894931</td>\n",
       "      <td>3.055691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4054.175414</td>\n",
       "      <td>2364.739039</td>\n",
       "      <td>3590.077431</td>\n",
       "      <td>-464.097984</td>\n",
       "      <td>1187.694358</td>\n",
       "      <td>-0.797484</td>\n",
       "      <td>-0.582127</td>\n",
       "      <td>1.410618e+06</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>50.729171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.075448</td>\n",
       "      <td>3.576688e+09</td>\n",
       "      <td>1.574383e+04</td>\n",
       "      <td>8.890063e+02</td>\n",
       "      <td>812.854860</td>\n",
       "      <td>145.044263</td>\n",
       "      <td>43.013947</td>\n",
       "      <td>2.302323</td>\n",
       "      <td>1.947904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2187.981464</td>\n",
       "      <td>2755.580822</td>\n",
       "      <td>3620.974382</td>\n",
       "      <td>1432.992918</td>\n",
       "      <td>695.837658</td>\n",
       "      <td>-0.312038</td>\n",
       "      <td>-1.245956</td>\n",
       "      <td>4.841900e+05</td>\n",
       "      <td>0.006904</td>\n",
       "      <td>59.065314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>0.136786</td>\n",
       "      <td>4.525491e+09</td>\n",
       "      <td>6.757636e+03</td>\n",
       "      <td>3.849655e+02</td>\n",
       "      <td>667.420601</td>\n",
       "      <td>125.166160</td>\n",
       "      <td>32.429763</td>\n",
       "      <td>1.707716</td>\n",
       "      <td>1.597904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2362.447080</td>\n",
       "      <td>8.122686</td>\n",
       "      <td>1420.377480</td>\n",
       "      <td>-942.069600</td>\n",
       "      <td>649.347508</td>\n",
       "      <td>0.350397</td>\n",
       "      <td>-0.977942</td>\n",
       "      <td>4.216522e+05</td>\n",
       "      <td>0.006834</td>\n",
       "      <td>68.005797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017123</td>\n",
       "      <td>0.088179</td>\n",
       "      <td>2.903698e+08</td>\n",
       "      <td>1.694703e+04</td>\n",
       "      <td>8.184609e+02</td>\n",
       "      <td>814.471830</td>\n",
       "      <td>120.684325</td>\n",
       "      <td>28.069911</td>\n",
       "      <td>2.113378</td>\n",
       "      <td>2.217117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      amplitude         mean           max          min        stdev  \\\n",
       "0  28600.257975  1245.670285  21471.069232 -7129.188743  7780.162127   \n",
       "1   7506.462109 -4965.798852   -476.438958 -7982.901067  2433.203314   \n",
       "2   4054.175414  2364.739039   3590.077431  -464.097984  1187.694358   \n",
       "3   2187.981464  2755.580822   3620.974382  1432.992918   695.837658   \n",
       "4   2362.447080     8.122686   1420.377480  -942.069600   649.347508   \n",
       "\n",
       "   skewness  kurtosis  hjorth_activity  hjorth_mobility  hjorth_complexity  \\\n",
       "0  0.765047 -0.610001     6.053092e+07         0.043994           6.488830   \n",
       "1  0.304853 -1.311260     5.920478e+06         0.005689          34.624977   \n",
       "2 -0.797484 -0.582127     1.410618e+06         0.005910          50.729171   \n",
       "3 -0.312038 -1.245956     4.841900e+05         0.006904          59.065314   \n",
       "4  0.350397 -0.977942     4.216522e+05         0.006834          68.005797   \n",
       "\n",
       "   ...  sample_entropy  spectral_entropy  energy_band_0  energy_band_1  \\\n",
       "0  ...        0.004544          0.055527   3.131736e+10   2.026249e+08   \n",
       "1  ...        0.012692          0.115011   1.725096e+10   2.053229e+04   \n",
       "2  ...        0.002690          0.075448   3.576688e+09   1.574383e+04   \n",
       "3  ...        0.015968          0.136786   4.525491e+09   6.757636e+03   \n",
       "4  ...        0.017123          0.088179   2.903698e+08   1.694703e+04   \n",
       "\n",
       "   energy_band_2  energy_band_3  energy_band_4  energy_band_5  energy_band_6  \\\n",
       "0   2.364575e+06  273852.478188    7335.565786   10011.650727   17660.037549   \n",
       "1   1.374747e+03    1052.824111     176.143959      67.214865       3.894931   \n",
       "2   8.890063e+02     812.854860     145.044263      43.013947       2.302323   \n",
       "3   3.849655e+02     667.420601     125.166160      32.429763       1.707716   \n",
       "4   8.184609e+02     814.471830     120.684325      28.069911       2.113378   \n",
       "\n",
       "   energy_band_7  \n",
       "0   11613.001761  \n",
       "1       3.055691  \n",
       "2       1.947904  \n",
       "3       1.597904  \n",
       "4       2.217117  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.to_csv(\"features.csv\")\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed features: ['max', 'min', 'stdev', 'hjorth_activity', 'delta_power', 'alpha_power', 'beta_power', 'gamma_power', 'sample_entropy', 'spectral_entropy', 'energy_band_0', 'energy_band_1', 'energy_band_2', 'energy_band_3', 'energy_band_5', 'energy_band_6', 'energy_band_7']\n"
     ]
    }
   ],
   "source": [
    "from features.utils import remove_collinear_features\n",
    "\n",
    "# Remove collinear features\n",
    "features = remove_collinear_features(features, threshold=0.6)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_train = 0.7\n",
    "n_train = int(prop_train * len(features))\n",
    "\n",
    "x_train = features[:n_train]\n",
    "y_train = all_targets[:n_train]\n",
    "\n",
    "x_val = features[n_train:]\n",
    "y_val = all_targets[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "\n",
    "selectKBest = SelectKBest(f_classif, k=20)\n",
    "\n",
    "x_train_sel = selectKBest.fit_transform(x_train, y_train)\n",
    "x_val_sel = selectKBest.transform(x_val)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 12/31 [07:55<06:11, 19.57s/it]  "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Fit all models\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(x_train, x_val, y_train, y_val)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
