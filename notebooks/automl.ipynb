{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the automated analysis of EEG quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will introduce you to the challenge by going through the data and working towards a first very simple model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's load the training data\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, lfilter\n",
    "import pandas as pd\n",
    "\n",
    "ROOT_PATH = Path(\"../data/train/\")\n",
    "training_data = [(np.load(ROOT_PATH / f\"data_{i}.npy\"),np.load(ROOT_PATH / f\"target_{i}.npy\")) for i in range(4)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect to have five channels and one label per channel for each two seconds of data.\n",
    "Let's have a look at the data duration and shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's filter the signal to improve the visualisation\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    return butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to get the point that maps to a label\n",
    "\n",
    "def reshape_array_into_windows(x, sample_rate, window_duration_in_seconds):\n",
    "    \"\"\"\n",
    "    Reshape the data into an array of shape (C, T, window) where 'window' contains\n",
    "    the points corresponding to 'window_duration' seconds of data.\n",
    "\n",
    "    Parameters:\n",
    "    x (numpy array): The input data array.\n",
    "    sample_rate (int): The number of samples per second.\n",
    "    window_duration_in_seconds (float): The duration of each window in seconds.\n",
    "\n",
    "    Returns:\n",
    "    reshaped_x (numpy array): The reshaped array with shape (C, T, window).\n",
    "    \"\"\"\n",
    "    # Calculate the number of samples in one window\n",
    "    window_size = int(window_duration_in_seconds * sample_rate)\n",
    "    \n",
    "    # Ensure the total length of x is a multiple of window_size\n",
    "    total_samples = x.shape[-1]\n",
    "    if total_samples % window_size != 0:\n",
    "        # Truncate or pad x to make it divisible by window_size\n",
    "        x = x[..., :total_samples - (total_samples % window_size)]\n",
    "    # Reshape x into (C, T, window)\n",
    "    reshaped_x = x.reshape(x.shape[0], -1, window_size)\n",
    "\n",
    "    return reshaped_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple model based on our observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first load and reshape all the data\n",
    "all_data = []\n",
    "all_targets = []\n",
    "for (data,target) in training_data:\n",
    "    filtered_data =  butter_bandpass_filter(data,0.1,18,250,4)\n",
    "    reshaped_data = reshape_array_into_windows(filtered_data,250,2)\n",
    "    targets_flatten = target[..., :len(reshaped_data[0])].reshape(-1)\n",
    "    reshaped_data = reshaped_data.reshape((-1,reshaped_data.shape[-1]))\n",
    "    all_data.append(reshaped_data)\n",
    "    all_targets.append(targets_flatten)\n",
    "all_data = np.concatenate(all_data)\n",
    "all_targets = np.concatenate(all_targets)\n",
    "assert all_data.shape[0] == all_targets.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amplitude</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>stdev</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>hjorth_activity</th>\n",
       "      <th>hjorth_mobility</th>\n",
       "      <th>hjorth_complexity</th>\n",
       "      <th>...</th>\n",
       "      <th>sample_entropy</th>\n",
       "      <th>spectral_entropy</th>\n",
       "      <th>energy_band_0</th>\n",
       "      <th>energy_band_1</th>\n",
       "      <th>energy_band_2</th>\n",
       "      <th>energy_band_3</th>\n",
       "      <th>energy_band_4</th>\n",
       "      <th>energy_band_5</th>\n",
       "      <th>energy_band_6</th>\n",
       "      <th>energy_band_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28600.257975</td>\n",
       "      <td>1245.670285</td>\n",
       "      <td>21471.069232</td>\n",
       "      <td>-7129.188743</td>\n",
       "      <td>7780.162127</td>\n",
       "      <td>0.765047</td>\n",
       "      <td>-0.610001</td>\n",
       "      <td>6.053092e+07</td>\n",
       "      <td>0.043994</td>\n",
       "      <td>6.488830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004544</td>\n",
       "      <td>0.055527</td>\n",
       "      <td>3.131736e+10</td>\n",
       "      <td>2.026249e+08</td>\n",
       "      <td>2.364575e+06</td>\n",
       "      <td>273852.478188</td>\n",
       "      <td>7335.565786</td>\n",
       "      <td>10011.650727</td>\n",
       "      <td>17660.037549</td>\n",
       "      <td>11613.001761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7506.462109</td>\n",
       "      <td>-4965.798852</td>\n",
       "      <td>-476.438958</td>\n",
       "      <td>-7982.901067</td>\n",
       "      <td>2433.203314</td>\n",
       "      <td>0.304853</td>\n",
       "      <td>-1.311260</td>\n",
       "      <td>5.920478e+06</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>34.624977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012692</td>\n",
       "      <td>0.115011</td>\n",
       "      <td>1.725096e+10</td>\n",
       "      <td>2.053229e+04</td>\n",
       "      <td>1.374747e+03</td>\n",
       "      <td>1052.824111</td>\n",
       "      <td>176.143959</td>\n",
       "      <td>67.214865</td>\n",
       "      <td>3.894931</td>\n",
       "      <td>3.055691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4054.175414</td>\n",
       "      <td>2364.739039</td>\n",
       "      <td>3590.077431</td>\n",
       "      <td>-464.097984</td>\n",
       "      <td>1187.694358</td>\n",
       "      <td>-0.797484</td>\n",
       "      <td>-0.582127</td>\n",
       "      <td>1.410618e+06</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>50.729171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.075448</td>\n",
       "      <td>3.576688e+09</td>\n",
       "      <td>1.574383e+04</td>\n",
       "      <td>8.890063e+02</td>\n",
       "      <td>812.854860</td>\n",
       "      <td>145.044263</td>\n",
       "      <td>43.013947</td>\n",
       "      <td>2.302323</td>\n",
       "      <td>1.947904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2187.981464</td>\n",
       "      <td>2755.580822</td>\n",
       "      <td>3620.974382</td>\n",
       "      <td>1432.992918</td>\n",
       "      <td>695.837658</td>\n",
       "      <td>-0.312038</td>\n",
       "      <td>-1.245956</td>\n",
       "      <td>4.841900e+05</td>\n",
       "      <td>0.006904</td>\n",
       "      <td>59.065314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>0.136786</td>\n",
       "      <td>4.525491e+09</td>\n",
       "      <td>6.757636e+03</td>\n",
       "      <td>3.849655e+02</td>\n",
       "      <td>667.420601</td>\n",
       "      <td>125.166160</td>\n",
       "      <td>32.429763</td>\n",
       "      <td>1.707716</td>\n",
       "      <td>1.597904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2362.447080</td>\n",
       "      <td>8.122686</td>\n",
       "      <td>1420.377480</td>\n",
       "      <td>-942.069600</td>\n",
       "      <td>649.347508</td>\n",
       "      <td>0.350397</td>\n",
       "      <td>-0.977942</td>\n",
       "      <td>4.216522e+05</td>\n",
       "      <td>0.006834</td>\n",
       "      <td>68.005797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017123</td>\n",
       "      <td>0.088179</td>\n",
       "      <td>2.903698e+08</td>\n",
       "      <td>1.694703e+04</td>\n",
       "      <td>8.184609e+02</td>\n",
       "      <td>814.471830</td>\n",
       "      <td>120.684325</td>\n",
       "      <td>28.069911</td>\n",
       "      <td>2.113378</td>\n",
       "      <td>2.217117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      amplitude         mean           max          min        stdev  \\\n",
       "0  28600.257975  1245.670285  21471.069232 -7129.188743  7780.162127   \n",
       "1   7506.462109 -4965.798852   -476.438958 -7982.901067  2433.203314   \n",
       "2   4054.175414  2364.739039   3590.077431  -464.097984  1187.694358   \n",
       "3   2187.981464  2755.580822   3620.974382  1432.992918   695.837658   \n",
       "4   2362.447080     8.122686   1420.377480  -942.069600   649.347508   \n",
       "\n",
       "   skewness  kurtosis  hjorth_activity  hjorth_mobility  hjorth_complexity  \\\n",
       "0  0.765047 -0.610001     6.053092e+07         0.043994           6.488830   \n",
       "1  0.304853 -1.311260     5.920478e+06         0.005689          34.624977   \n",
       "2 -0.797484 -0.582127     1.410618e+06         0.005910          50.729171   \n",
       "3 -0.312038 -1.245956     4.841900e+05         0.006904          59.065314   \n",
       "4  0.350397 -0.977942     4.216522e+05         0.006834          68.005797   \n",
       "\n",
       "   ...  sample_entropy  spectral_entropy  energy_band_0  energy_band_1  \\\n",
       "0  ...        0.004544          0.055527   3.131736e+10   2.026249e+08   \n",
       "1  ...        0.012692          0.115011   1.725096e+10   2.053229e+04   \n",
       "2  ...        0.002690          0.075448   3.576688e+09   1.574383e+04   \n",
       "3  ...        0.015968          0.136786   4.525491e+09   6.757636e+03   \n",
       "4  ...        0.017123          0.088179   2.903698e+08   1.694703e+04   \n",
       "\n",
       "   energy_band_2  energy_band_3  energy_band_4  energy_band_5  energy_band_6  \\\n",
       "0   2.364575e+06  273852.478188    7335.565786   10011.650727   17660.037549   \n",
       "1   1.374747e+03    1052.824111     176.143959      67.214865       3.894931   \n",
       "2   8.890063e+02     812.854860     145.044263      43.013947       2.302323   \n",
       "3   3.849655e+02     667.420601     125.166160      32.429763       1.707716   \n",
       "4   8.184609e+02     814.471830     120.684325      28.069911       2.113378   \n",
       "\n",
       "   energy_band_7  \n",
       "0   11613.001761  \n",
       "1       3.055691  \n",
       "2       1.947904  \n",
       "3       1.597904  \n",
       "4       2.217117  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv(\"features/features.csv\", index_col=0)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We train a model on 70% of the data and evaluate the model on the remaining 30%\n",
    "prop_train = 0.7\n",
    "n_train = int(prop_train * len(features))\n",
    "\n",
    "x_train = features[:n_train]\n",
    "y_train = all_targets[:n_train]\n",
    "\n",
    "x_val = features[n_train:]\n",
    "y_val = all_targets[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                   \n",
      "Generation 1 - Current best internal CV score: 0.9408058660414016\n",
      "                                                                                    \n",
      "Generation 2 - Current best internal CV score: 0.9408058660414016\n",
      "                                                                                    \n",
      "Generation 3 - Current best internal CV score: 0.9408058660414016\n",
      "                                                                                   \n",
      "Generation 4 - Current best internal CV score: 0.9408058660414016\n",
      "                                                                                \n",
      "Generation 5 - Current best internal CV score: 0.9408058660414016\n",
      "                                                             \n",
      "Best pipeline: ExtraTreesClassifier(input_matrix, bootstrap=False, criterion=entropy, max_features=0.7000000000000001, min_samples_leaf=11, min_samples_split=4, n_estimators=100)\n"
     ]
    }
   ],
   "source": [
    "from models.automl import train_automl_model\n",
    "\n",
    "# Train the AutoML model\n",
    "model = train_automl_model(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen:  0.6903692881768673\n",
      "F1 score:  0.7940495245268807\n"
     ]
    }
   ],
   "source": [
    "from models.automl import evaluate_model\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(\"models/automl_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now evaluate the cohen kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What do you think of the performances ?\n",
    "- What do you think of the split strategy ?\n",
    "- What are additional features you could use ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model on the test data and submitting to the leaderboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features.frequency_domain_features import extract_frequency_domain_features_multichannel\n",
    "from features.time_domain_features import extract_time_domain_features\n",
    "from features.complexity_features import extract_multichannel_entropy_features\n",
    "from features.wavelet_decomposition import extract_wavelet_energy_features_multichannel\n",
    "\n",
    "ROOT_TEST_PATH = Path(\"../data/test/\")\n",
    "test_data = {i:np.load(ROOT_TEST_PATH / f\"data_{i}.npy\") for i in [4,5]}\n",
    "# We process each record independantly\n",
    "\n",
    "def compute_features_on_record(data):\n",
    "    \"\"\"\n",
    "    We compute each of the feature for each window and each channel\n",
    "    Each value of the output dict has shape (Channels,T)\n",
    "    \"\"\"\n",
    "    filtered_data =  butter_bandpass_filter(data,0.1,18,250,4)\n",
    "    reshaped_data = reshape_array_into_windows(filtered_data,250,2)\n",
    "    print(\"Before any feature extraction: \", reshaped_data.shape)\n",
    "    \n",
    "    time_features = extract_time_domain_features(reshaped_data, return_type=\"numpy\")\n",
    "    print(\"Time features shape: \", {k: time_features[k].shape for k in time_features})\n",
    "\n",
    "    frequency_features = extract_frequency_domain_features_multichannel(reshaped_data)\n",
    "    print(\"Frequency features shape: \", {k: frequency_features[k].shape for k in frequency_features})\n",
    "\n",
    "    entropy_features = extract_multichannel_entropy_features(reshaped_data)\n",
    "    print(\"Entropy features shape: \", {k: entropy_features[k].shape for k in entropy_features})\n",
    "\n",
    "    wavelet_energy_features_multichannel = extract_wavelet_energy_features_multichannel(reshaped_data)\n",
    "    print(\"Wavelet energy features shape: \", {k: wavelet_energy_features_multichannel[k].shape for k in wavelet_energy_features_multichannel})\n",
    "    \n",
    "    features = {**time_features, **frequency_features, **entropy_features, **wavelet_energy_features_multichannel}\n",
    "    print(\"Features shape: \", {k:features[k].shape for k in features})\n",
    "    \n",
    "    return features  # {5 ch x 13k, 5 ch x 13k, . . .}\n",
    "\n",
    "\n",
    "\n",
    "def compute_predictions_on_record(data,model,features_name_for_model):\n",
    "    predictions = []\n",
    "    features = compute_features_on_record(data)\n",
    "    features = np.array([features[k] for k in features_name_for_model]) \n",
    "    features = features.swapaxes(0,1).swapaxes(1,2)\n",
    "    for channel in range(features.shape[0]):\n",
    "        predictions.append(model.predict(features[channel]))\n",
    "    return np.array(predictions)\n",
    "\n",
    "def format_array_to_target_format(array, record_number):\n",
    "    assert isinstance(record_number, int)\n",
    "    assert isinstance(array, np.ndarray)\n",
    "    assert len(array.shape) == 2\n",
    "    assert array.shape[0] == 5\n",
    "    print(set(np.unique(array)))\n",
    "    assert set(np.unique(array)) == {0, 1}\n",
    "    formatted_target = []\n",
    "    for i in range(array.shape[0]):\n",
    "        channel_encoding = (i + 1) * 100000\n",
    "        record_number_encoding = record_number * 1000000\n",
    "        for j in range(array.shape[1]):\n",
    "            formatted_target.append(\n",
    "                {\n",
    "                    \"identifier\": record_number_encoding + channel_encoding + j,\n",
    "                    \"target\": array[i, j],\n",
    "                }\n",
    "            )\n",
    "    return formatted_target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the functions defined above, we can now run the model and submit the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before any feature extraction:  (5, 13204, 500)\n",
      "Time features shape:  {'amplitude': (5, 13204), 'mean': (5, 13204), 'max': (5, 13204), 'min': (5, 13204), 'stdev': (5, 13204), 'skewness': (5, 13204), 'kurtosis': (5, 13204), 'hjorth_activity': (5, 13204), 'hjorth_mobility': (5, 13204), 'hjorth_complexity': (5, 13204)}\n",
      "Frequency features shape:  {'delta_power': (5, 13204), 'theta_power': (5, 13204), 'alpha_power': (5, 13204), 'beta_power': (5, 13204), 'gamma_power': (5, 13204)}\n",
      "Entropy features shape:  {'shannon_entropy': (5, 13204), 'sample_entropy': (5, 13204), 'spectral_entropy': (5, 13204)}\n",
      "Wavelet energy features shape:  {'energy_band_0': (5, 13204), 'energy_band_1': (5, 13204), 'energy_band_2': (5, 13204), 'energy_band_3': (5, 13204), 'energy_band_4': (5, 13204), 'energy_band_5': (5, 13204), 'energy_band_6': (5, 13204), 'energy_band_7': (5, 13204)}\n",
      "Features shape:  {'amplitude': (5, 13204), 'mean': (5, 13204), 'max': (5, 13204), 'min': (5, 13204), 'stdev': (5, 13204), 'skewness': (5, 13204), 'kurtosis': (5, 13204), 'hjorth_activity': (5, 13204), 'hjorth_mobility': (5, 13204), 'hjorth_complexity': (5, 13204), 'delta_power': (5, 13204), 'theta_power': (5, 13204), 'alpha_power': (5, 13204), 'beta_power': (5, 13204), 'gamma_power': (5, 13204), 'shannon_entropy': (5, 13204), 'sample_entropy': (5, 13204), 'spectral_entropy': (5, 13204), 'energy_band_0': (5, 13204), 'energy_band_1': (5, 13204), 'energy_band_2': (5, 13204), 'energy_band_3': (5, 13204), 'energy_band_4': (5, 13204), 'energy_band_5': (5, 13204), 'energy_band_6': (5, 13204), 'energy_band_7': (5, 13204)}\n",
      "{0, 1}\n",
      "Before any feature extraction:  (5, 9319, 500)\n",
      "Time features shape:  {'amplitude': (5, 9319), 'mean': (5, 9319), 'max': (5, 9319), 'min': (5, 9319), 'stdev': (5, 9319), 'skewness': (5, 9319), 'kurtosis': (5, 9319), 'hjorth_activity': (5, 9319), 'hjorth_mobility': (5, 9319), 'hjorth_complexity': (5, 9319)}\n",
      "Frequency features shape:  {'delta_power': (5, 9319), 'theta_power': (5, 9319), 'alpha_power': (5, 9319), 'beta_power': (5, 9319), 'gamma_power': (5, 9319)}\n",
      "Entropy features shape:  {'shannon_entropy': (5, 9319), 'sample_entropy': (5, 9319), 'spectral_entropy': (5, 9319)}\n",
      "Wavelet energy features shape:  {'energy_band_0': (5, 9319), 'energy_band_1': (5, 9319), 'energy_band_2': (5, 9319), 'energy_band_3': (5, 9319), 'energy_band_4': (5, 9319), 'energy_band_5': (5, 9319), 'energy_band_6': (5, 9319), 'energy_band_7': (5, 9319)}\n",
      "Features shape:  {'amplitude': (5, 9319), 'mean': (5, 9319), 'max': (5, 9319), 'min': (5, 9319), 'stdev': (5, 9319), 'skewness': (5, 9319), 'kurtosis': (5, 9319), 'hjorth_activity': (5, 9319), 'hjorth_mobility': (5, 9319), 'hjorth_complexity': (5, 9319), 'delta_power': (5, 9319), 'theta_power': (5, 9319), 'alpha_power': (5, 9319), 'beta_power': (5, 9319), 'gamma_power': (5, 9319), 'shannon_entropy': (5, 9319), 'sample_entropy': (5, 9319), 'spectral_entropy': (5, 9319), 'energy_band_0': (5, 9319), 'energy_band_1': (5, 9319), 'energy_band_2': (5, 9319), 'energy_band_3': (5, 9319), 'energy_band_4': (5, 9319), 'energy_band_5': (5, 9319), 'energy_band_6': (5, 9319), 'energy_band_7': (5, 9319)}\n",
      "{0, 1}\n"
     ]
    }
   ],
   "source": [
    "from models.features_list import best_features\n",
    "\n",
    "results = []\n",
    "for record_number, data in test_data.items():\n",
    "    preds = compute_predictions_on_record(data, model, best_features)\n",
    "    formatted_preds = format_array_to_target_format(preds,record_number)\n",
    "    results.extend(formatted_preds)\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"../results/auto-ml.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112615"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv(\"../results/auto-ml.csv\")\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
