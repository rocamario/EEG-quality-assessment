{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the automated analysis of EEG quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will introduce you to the challenge by going through the data and working towards a first very simple model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's load the training data\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, lfilter\n",
    "import pandas as pd\n",
    "\n",
    "ROOT_PATH = Path(\"../data/train/\")\n",
    "training_data = [(np.load(ROOT_PATH / f\"data_{i}.npy\"),np.load(ROOT_PATH / f\"target_{i}.npy\")) for i in range(4)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect to have five channels and one label per channel for each two seconds of data.\n",
    "Let's have a look at the data duration and shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove the DC component and high frequency component we apply a band-pass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's filter the signal to improve the visualisation\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    return butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that some of the high amplitude is classified as bad quality, we could use that to build a first simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the statistics of the good and bad quality EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to get the point that maps to a label\n",
    "\n",
    "def reshape_array_into_windows(x, sample_rate, window_duration_in_seconds):\n",
    "    \"\"\"\n",
    "    Reshape the data into an array of shape (C, T, window) where 'window' contains\n",
    "    the points corresponding to 'window_duration' seconds of data.\n",
    "\n",
    "    Parameters:\n",
    "    x (numpy array): The input data array.\n",
    "    sample_rate (int): The number of samples per second.\n",
    "    window_duration_in_seconds (float): The duration of each window in seconds.\n",
    "\n",
    "    Returns:\n",
    "    reshaped_x (numpy array): The reshaped array with shape (C, T, window).\n",
    "    \"\"\"\n",
    "    # Calculate the number of samples in one window\n",
    "    window_size = int(window_duration_in_seconds * sample_rate)\n",
    "    \n",
    "    # Ensure the total length of x is a multiple of window_size\n",
    "    total_samples = x.shape[-1]\n",
    "    if total_samples % window_size != 0:\n",
    "        # Truncate or pad x to make it divisible by window_size\n",
    "        x = x[..., :total_samples - (total_samples % window_size)]\n",
    "    # Reshape x into (C, T, window)\n",
    "    reshaped_x = x.reshape(x.shape[0], -1, window_size)\n",
    "\n",
    "    return reshaped_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a XGBOOST Classifier model based on our observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first load and reshape all the data\n",
    "all_data = []\n",
    "all_targets = []\n",
    "for (data,target) in training_data:\n",
    "    filtered_data =  butter_bandpass_filter(data,0.1,18,250,4)\n",
    "    reshaped_data = reshape_array_into_windows(filtered_data,250,2)\n",
    "    targets_flatten = target[..., :len(reshaped_data[0])].reshape(-1)\n",
    "    reshaped_data = reshaped_data.reshape((-1,reshaped_data.shape[-1]))\n",
    "    all_data.append(reshaped_data)\n",
    "    all_targets.append(targets_flatten)\n",
    "all_data = np.concatenate(all_data)\n",
    "all_targets = np.concatenate(all_targets)\n",
    "assert all_data.shape[0] == all_targets.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amplitude</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>stdev</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>hjorth_activity</th>\n",
       "      <th>hjorth_mobility</th>\n",
       "      <th>hjorth_complexity</th>\n",
       "      <th>...</th>\n",
       "      <th>sample_entropy</th>\n",
       "      <th>spectral_entropy</th>\n",
       "      <th>energy_band_0</th>\n",
       "      <th>energy_band_1</th>\n",
       "      <th>energy_band_2</th>\n",
       "      <th>energy_band_3</th>\n",
       "      <th>energy_band_4</th>\n",
       "      <th>energy_band_5</th>\n",
       "      <th>energy_band_6</th>\n",
       "      <th>energy_band_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28600.257975</td>\n",
       "      <td>1245.670285</td>\n",
       "      <td>21471.069232</td>\n",
       "      <td>-7129.188743</td>\n",
       "      <td>7780.162127</td>\n",
       "      <td>0.765047</td>\n",
       "      <td>-0.610001</td>\n",
       "      <td>6.053092e+07</td>\n",
       "      <td>0.043994</td>\n",
       "      <td>6.488830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004544</td>\n",
       "      <td>0.055527</td>\n",
       "      <td>3.131736e+10</td>\n",
       "      <td>2.026249e+08</td>\n",
       "      <td>2.364575e+06</td>\n",
       "      <td>273852.478188</td>\n",
       "      <td>7335.565786</td>\n",
       "      <td>10011.650727</td>\n",
       "      <td>17660.037549</td>\n",
       "      <td>11613.001761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7506.462109</td>\n",
       "      <td>-4965.798852</td>\n",
       "      <td>-476.438958</td>\n",
       "      <td>-7982.901067</td>\n",
       "      <td>2433.203314</td>\n",
       "      <td>0.304853</td>\n",
       "      <td>-1.311260</td>\n",
       "      <td>5.920478e+06</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>34.624977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012692</td>\n",
       "      <td>0.115011</td>\n",
       "      <td>1.725096e+10</td>\n",
       "      <td>2.053229e+04</td>\n",
       "      <td>1.374747e+03</td>\n",
       "      <td>1052.824111</td>\n",
       "      <td>176.143959</td>\n",
       "      <td>67.214865</td>\n",
       "      <td>3.894931</td>\n",
       "      <td>3.055691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4054.175414</td>\n",
       "      <td>2364.739039</td>\n",
       "      <td>3590.077431</td>\n",
       "      <td>-464.097984</td>\n",
       "      <td>1187.694358</td>\n",
       "      <td>-0.797484</td>\n",
       "      <td>-0.582127</td>\n",
       "      <td>1.410618e+06</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>50.729171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.075448</td>\n",
       "      <td>3.576688e+09</td>\n",
       "      <td>1.574383e+04</td>\n",
       "      <td>8.890063e+02</td>\n",
       "      <td>812.854860</td>\n",
       "      <td>145.044263</td>\n",
       "      <td>43.013947</td>\n",
       "      <td>2.302323</td>\n",
       "      <td>1.947904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2187.981464</td>\n",
       "      <td>2755.580822</td>\n",
       "      <td>3620.974382</td>\n",
       "      <td>1432.992918</td>\n",
       "      <td>695.837658</td>\n",
       "      <td>-0.312038</td>\n",
       "      <td>-1.245956</td>\n",
       "      <td>4.841900e+05</td>\n",
       "      <td>0.006904</td>\n",
       "      <td>59.065314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>0.136786</td>\n",
       "      <td>4.525491e+09</td>\n",
       "      <td>6.757636e+03</td>\n",
       "      <td>3.849655e+02</td>\n",
       "      <td>667.420601</td>\n",
       "      <td>125.166160</td>\n",
       "      <td>32.429763</td>\n",
       "      <td>1.707716</td>\n",
       "      <td>1.597904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2362.447080</td>\n",
       "      <td>8.122686</td>\n",
       "      <td>1420.377480</td>\n",
       "      <td>-942.069600</td>\n",
       "      <td>649.347508</td>\n",
       "      <td>0.350397</td>\n",
       "      <td>-0.977942</td>\n",
       "      <td>4.216522e+05</td>\n",
       "      <td>0.006834</td>\n",
       "      <td>68.005797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017123</td>\n",
       "      <td>0.088179</td>\n",
       "      <td>2.903698e+08</td>\n",
       "      <td>1.694703e+04</td>\n",
       "      <td>8.184609e+02</td>\n",
       "      <td>814.471830</td>\n",
       "      <td>120.684325</td>\n",
       "      <td>28.069911</td>\n",
       "      <td>2.113378</td>\n",
       "      <td>2.217117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      amplitude         mean           max          min        stdev  \\\n",
       "0  28600.257975  1245.670285  21471.069232 -7129.188743  7780.162127   \n",
       "1   7506.462109 -4965.798852   -476.438958 -7982.901067  2433.203314   \n",
       "2   4054.175414  2364.739039   3590.077431  -464.097984  1187.694358   \n",
       "3   2187.981464  2755.580822   3620.974382  1432.992918   695.837658   \n",
       "4   2362.447080     8.122686   1420.377480  -942.069600   649.347508   \n",
       "\n",
       "   skewness  kurtosis  hjorth_activity  hjorth_mobility  hjorth_complexity  \\\n",
       "0  0.765047 -0.610001     6.053092e+07         0.043994           6.488830   \n",
       "1  0.304853 -1.311260     5.920478e+06         0.005689          34.624977   \n",
       "2 -0.797484 -0.582127     1.410618e+06         0.005910          50.729171   \n",
       "3 -0.312038 -1.245956     4.841900e+05         0.006904          59.065314   \n",
       "4  0.350397 -0.977942     4.216522e+05         0.006834          68.005797   \n",
       "\n",
       "   ...  sample_entropy  spectral_entropy  energy_band_0  energy_band_1  \\\n",
       "0  ...        0.004544          0.055527   3.131736e+10   2.026249e+08   \n",
       "1  ...        0.012692          0.115011   1.725096e+10   2.053229e+04   \n",
       "2  ...        0.002690          0.075448   3.576688e+09   1.574383e+04   \n",
       "3  ...        0.015968          0.136786   4.525491e+09   6.757636e+03   \n",
       "4  ...        0.017123          0.088179   2.903698e+08   1.694703e+04   \n",
       "\n",
       "   energy_band_2  energy_band_3  energy_band_4  energy_band_5  energy_band_6  \\\n",
       "0   2.364575e+06  273852.478188    7335.565786   10011.650727   17660.037549   \n",
       "1   1.374747e+03    1052.824111     176.143959      67.214865       3.894931   \n",
       "2   8.890063e+02     812.854860     145.044263      43.013947       2.302323   \n",
       "3   3.849655e+02     667.420601     125.166160      32.429763       1.707716   \n",
       "4   8.184609e+02     814.471830     120.684325      28.069911       2.113378   \n",
       "\n",
       "   energy_band_7  \n",
       "0   11613.001761  \n",
       "1       3.055691  \n",
       "2       1.947904  \n",
       "3       1.597904  \n",
       "4       2.217117  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv(\"features.csv\", index_col=0)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed features: ['max', 'min', 'stdev', 'hjorth_activity', 'delta_power', 'alpha_power', 'beta_power', 'gamma_power', 'sample_entropy', 'spectral_entropy', 'energy_band_0', 'energy_band_1', 'energy_band_2', 'energy_band_3', 'energy_band_5', 'energy_band_6', 'energy_band_7']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amplitude</th>\n",
       "      <th>mean</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>hjorth_mobility</th>\n",
       "      <th>hjorth_complexity</th>\n",
       "      <th>theta_power</th>\n",
       "      <th>shannon_entropy</th>\n",
       "      <th>energy_band_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28600.257975</td>\n",
       "      <td>1245.670285</td>\n",
       "      <td>0.765047</td>\n",
       "      <td>-0.610001</td>\n",
       "      <td>0.043994</td>\n",
       "      <td>6.488830</td>\n",
       "      <td>422.099286</td>\n",
       "      <td>0.300821</td>\n",
       "      <td>7335.565786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7506.462109</td>\n",
       "      <td>-4965.798852</td>\n",
       "      <td>0.304853</td>\n",
       "      <td>-1.311260</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>34.624977</td>\n",
       "      <td>529.876066</td>\n",
       "      <td>0.749798</td>\n",
       "      <td>176.143959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4054.175414</td>\n",
       "      <td>2364.739039</td>\n",
       "      <td>-0.797484</td>\n",
       "      <td>-0.582127</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>50.729171</td>\n",
       "      <td>155.719216</td>\n",
       "      <td>0.747064</td>\n",
       "      <td>145.044263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2187.981464</td>\n",
       "      <td>2755.580822</td>\n",
       "      <td>-0.312038</td>\n",
       "      <td>-1.245956</td>\n",
       "      <td>0.006904</td>\n",
       "      <td>59.065314</td>\n",
       "      <td>362.701007</td>\n",
       "      <td>1.113054</td>\n",
       "      <td>125.166160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2362.447080</td>\n",
       "      <td>8.122686</td>\n",
       "      <td>0.350397</td>\n",
       "      <td>-0.977942</td>\n",
       "      <td>0.006834</td>\n",
       "      <td>68.005797</td>\n",
       "      <td>100.716290</td>\n",
       "      <td>1.015574</td>\n",
       "      <td>120.684325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      amplitude         mean  skewness  kurtosis  hjorth_mobility  \\\n",
       "0  28600.257975  1245.670285  0.765047 -0.610001         0.043994   \n",
       "1   7506.462109 -4965.798852  0.304853 -1.311260         0.005689   \n",
       "2   4054.175414  2364.739039 -0.797484 -0.582127         0.005910   \n",
       "3   2187.981464  2755.580822 -0.312038 -1.245956         0.006904   \n",
       "4   2362.447080     8.122686  0.350397 -0.977942         0.006834   \n",
       "\n",
       "   hjorth_complexity  theta_power  shannon_entropy  energy_band_4  \n",
       "0           6.488830   422.099286         0.300821    7335.565786  \n",
       "1          34.624977   529.876066         0.749798     176.143959  \n",
       "2          50.729171   155.719216         0.747064     145.044263  \n",
       "3          59.065314   362.701007         1.113054     125.166160  \n",
       "4          68.005797   100.716290         1.015574     120.684325  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from features.utils import remove_collinear_features\n",
    "\n",
    "# Remove collinear features\n",
    "features = remove_collinear_features(features, threshold=0.6)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa: 0.8789606108469012\n",
      "F1 Score: 0.9513204351924337\n",
      "Cohen's Kappa: 0.8775750197476239\n",
      "F1 Score: 0.9507573336741868\n",
      "Cohen's Kappa: 0.879366453561998\n",
      "F1 Score: 0.9513752220035521\n",
      "Cohen's Kappa: 0.8829990931093434\n",
      "F1 Score: 0.9529122178888818\n",
      "Cohen's Kappa: 0.880826643224924\n",
      "F1 Score: 0.9521209508756805\n",
      "Fold 1 evaluation result: None\n",
      "Fold 2 evaluation result: None\n",
      "Fold 3 evaluation result: None\n",
      "Fold 4 evaluation result: None\n",
      "Fold 5 evaluation result: None\n"
     ]
    }
   ],
   "source": [
    "# We train a model on 70% of the data and evaluate the model on the remaining 30%\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from models.xgboost import train_xgboost_model, evaluate_model\n",
    "\n",
    "# Define the number of splits for k-fold cross-validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store evaluation results\n",
    "evaluation_results = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, val_index in skf.split(features, all_targets):\n",
    "    x_train, x_val = features.iloc[train_index], features.iloc[val_index]\n",
    "    y_train, y_val = all_targets[train_index], all_targets[val_index]\n",
    "    \n",
    "    # Train the model\n",
    "    model = train_xgboost_model(x_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    evaluation_result = evaluate_model(model, x_val, y_val)\n",
    "    evaluation_results.append(evaluation_result)\n",
    "\n",
    "# Print the evaluation results\n",
    "for i, result in enumerate(evaluation_results):\n",
    "    print(f\"Fold {i+1} evaluation result: {result}\")\n",
    "\n",
    "# Train the final model on the entire dataset\n",
    "model = train_xgboost_model(features, all_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now evaluate the cohen kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What do you think of the performances ?\n",
    "- What do you think of the split strategy ?\n",
    "- What are additional features you could use ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model on the test data and submitting to the leaderboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features.frequency_domain_features import extract_frequency_domain_features_multichannel\n",
    "from features.complexity_features import extract_multichannel_entropy_features\n",
    "from features.wavelet_decomposition import extract_wavelet_energy_features_multichannel\n",
    "from features.time_domain_features import extract_time_domain_features\n",
    "import xgboost as xgb\n",
    "from models.features_list import list_features, collinear_features\n",
    "\n",
    "ROOT_TEST_PATH = Path(\"../data/test/\")\n",
    "test_data = {i:np.load(ROOT_TEST_PATH / f\"data_{i}.npy\") for i in [4,5]}\n",
    "# We process each record independantly\n",
    "\n",
    "def compute_features_on_record(data):\n",
    "    \"\"\"\n",
    "    We compute each of the feature for each window and each channel\n",
    "    Each value of the output dict has shape (Channels,T)\n",
    "    \"\"\"\n",
    "    filtered_data =  butter_bandpass_filter(data,0.1,18,250,4)\n",
    "    reshaped_data = reshape_array_into_windows(filtered_data,250,2)\n",
    "    print(\"Before any feature extraction: \", reshaped_data.shape)\n",
    "    \n",
    "    time_features = extract_time_domain_features(reshaped_data, return_type=\"numpy\")\n",
    "    print(\"Time features shape: \", {k: time_features[k].shape for k in time_features})\n",
    "\n",
    "    frequency_features = extract_frequency_domain_features_multichannel(reshaped_data)\n",
    "    print(\"Frequency features shape: \", {k: frequency_features[k].shape for k in frequency_features})\n",
    "\n",
    "    entropy_features = extract_multichannel_entropy_features(reshaped_data)\n",
    "    print(\"Entropy features shape: \", {k: entropy_features[k].shape for k in entropy_features})\n",
    "\n",
    "    wavelet_features = extract_wavelet_energy_features_multichannel(reshaped_data)\n",
    "    print(\"Wavelet features shape: \", {k: wavelet_features[k].shape for k in wavelet_features})\n",
    "\n",
    "    features = {**time_features, **frequency_features, **entropy_features, **wavelet_features}\n",
    "    print(\"Features shape: \", {k:features[k].shape for k in features})\n",
    "    print(\"Features name: \", list(features.keys()))\n",
    "    \n",
    "    return features  # {5 ch x 13k, 5 ch x 13k, . . .}\n",
    "\n",
    "def compute_predictions_on_record(data,model,features_name_for_model):\n",
    "    predictions = []\n",
    "    features = compute_features_on_record(data)\n",
    "\n",
    "    features = np.array([features[k] for k in features_name_for_model])  # (26, 5, 13000)\n",
    "    print(\"Features shape for model: \", features.shape)\n",
    "    features = features.swapaxes(0,1).swapaxes(1,2)  # (5, 13000, 26)\n",
    "    \n",
    "    print(\"Features shape for model: \", features.shape)\n",
    "    for channel in range(features.shape[0]):\n",
    "        features_df = pd.DataFrame(features[channel], columns=list_features)\n",
    "        features_df.to_csv(f\"features/test/features_test_channel_{channel}.csv\")\n",
    "        predictions.append(\n",
    "            np.round(\n",
    "                model.predict(\n",
    "                    xgb.DMatrix(\n",
    "                        data=features_df[collinear_features]\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    return np.array(predictions)\n",
    "\n",
    "def format_array_to_target_format(array, record_number):\n",
    "    assert isinstance(record_number, int)\n",
    "    assert isinstance(array, np.ndarray)\n",
    "    assert len(array.shape) == 2\n",
    "    assert array.shape[0] == 5\n",
    "    print(set(np.unique(array)))\n",
    "    assert set(np.unique(array)) == {0, 1}\n",
    "    formatted_target = []\n",
    "    for i in range(array.shape[0]):\n",
    "        channel_encoding = (i + 1) * 100000\n",
    "        record_number_encoding = record_number * 1000000\n",
    "        for j in range(array.shape[1]):\n",
    "            formatted_target.append(\n",
    "                {\n",
    "                    \"identifier\": record_number_encoding + channel_encoding + j,\n",
    "                    \"target\": array[i, j],\n",
    "                }\n",
    "            )\n",
    "    return formatted_target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the functions defined above, we can now run the model and submit the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before any feature extraction:  (5, 13204, 500)\n",
      "Time features shape:  {'amplitude': (5, 13204), 'mean': (5, 13204), 'max': (5, 13204), 'min': (5, 13204), 'stdev': (5, 13204), 'skewness': (5, 13204), 'kurtosis': (5, 13204), 'hjorth_activity': (5, 13204), 'hjorth_mobility': (5, 13204), 'hjorth_complexity': (5, 13204)}\n",
      "Frequency features shape:  {'delta_power': (5, 13204), 'theta_power': (5, 13204), 'alpha_power': (5, 13204), 'beta_power': (5, 13204), 'gamma_power': (5, 13204)}\n",
      "Entropy features shape:  {'shannon_entropy': (5, 13204), 'sample_entropy': (5, 13204), 'spectral_entropy': (5, 13204)}\n",
      "Wavelet features shape:  {'energy_band_0': (5, 13204), 'energy_band_1': (5, 13204), 'energy_band_2': (5, 13204), 'energy_band_3': (5, 13204), 'energy_band_4': (5, 13204), 'energy_band_5': (5, 13204), 'energy_band_6': (5, 13204), 'energy_band_7': (5, 13204)}\n",
      "Features shape:  {'amplitude': (5, 13204), 'mean': (5, 13204), 'max': (5, 13204), 'min': (5, 13204), 'stdev': (5, 13204), 'skewness': (5, 13204), 'kurtosis': (5, 13204), 'hjorth_activity': (5, 13204), 'hjorth_mobility': (5, 13204), 'hjorth_complexity': (5, 13204), 'delta_power': (5, 13204), 'theta_power': (5, 13204), 'alpha_power': (5, 13204), 'beta_power': (5, 13204), 'gamma_power': (5, 13204), 'shannon_entropy': (5, 13204), 'sample_entropy': (5, 13204), 'spectral_entropy': (5, 13204), 'energy_band_0': (5, 13204), 'energy_band_1': (5, 13204), 'energy_band_2': (5, 13204), 'energy_band_3': (5, 13204), 'energy_band_4': (5, 13204), 'energy_band_5': (5, 13204), 'energy_band_6': (5, 13204), 'energy_band_7': (5, 13204)}\n",
      "Features name:  ['amplitude', 'mean', 'max', 'min', 'stdev', 'skewness', 'kurtosis', 'hjorth_activity', 'hjorth_mobility', 'hjorth_complexity', 'delta_power', 'theta_power', 'alpha_power', 'beta_power', 'gamma_power', 'shannon_entropy', 'sample_entropy', 'spectral_entropy', 'energy_band_0', 'energy_band_1', 'energy_band_2', 'energy_band_3', 'energy_band_4', 'energy_band_5', 'energy_band_6', 'energy_band_7']\n",
      "Features shape for model:  (26, 5, 13204)\n",
      "Features shape for model:  (5, 13204, 26)\n",
      "{0.0, 1.0}\n",
      "Before any feature extraction:  (5, 9319, 500)\n",
      "Time features shape:  {'amplitude': (5, 9319), 'mean': (5, 9319), 'max': (5, 9319), 'min': (5, 9319), 'stdev': (5, 9319), 'skewness': (5, 9319), 'kurtosis': (5, 9319), 'hjorth_activity': (5, 9319), 'hjorth_mobility': (5, 9319), 'hjorth_complexity': (5, 9319)}\n",
      "Frequency features shape:  {'delta_power': (5, 9319), 'theta_power': (5, 9319), 'alpha_power': (5, 9319), 'beta_power': (5, 9319), 'gamma_power': (5, 9319)}\n",
      "Entropy features shape:  {'shannon_entropy': (5, 9319), 'sample_entropy': (5, 9319), 'spectral_entropy': (5, 9319)}\n",
      "Wavelet features shape:  {'energy_band_0': (5, 9319), 'energy_band_1': (5, 9319), 'energy_band_2': (5, 9319), 'energy_band_3': (5, 9319), 'energy_band_4': (5, 9319), 'energy_band_5': (5, 9319), 'energy_band_6': (5, 9319), 'energy_band_7': (5, 9319)}\n",
      "Features shape:  {'amplitude': (5, 9319), 'mean': (5, 9319), 'max': (5, 9319), 'min': (5, 9319), 'stdev': (5, 9319), 'skewness': (5, 9319), 'kurtosis': (5, 9319), 'hjorth_activity': (5, 9319), 'hjorth_mobility': (5, 9319), 'hjorth_complexity': (5, 9319), 'delta_power': (5, 9319), 'theta_power': (5, 9319), 'alpha_power': (5, 9319), 'beta_power': (5, 9319), 'gamma_power': (5, 9319), 'shannon_entropy': (5, 9319), 'sample_entropy': (5, 9319), 'spectral_entropy': (5, 9319), 'energy_band_0': (5, 9319), 'energy_band_1': (5, 9319), 'energy_band_2': (5, 9319), 'energy_band_3': (5, 9319), 'energy_band_4': (5, 9319), 'energy_band_5': (5, 9319), 'energy_band_6': (5, 9319), 'energy_band_7': (5, 9319)}\n",
      "Features name:  ['amplitude', 'mean', 'max', 'min', 'stdev', 'skewness', 'kurtosis', 'hjorth_activity', 'hjorth_mobility', 'hjorth_complexity', 'delta_power', 'theta_power', 'alpha_power', 'beta_power', 'gamma_power', 'shannon_entropy', 'sample_entropy', 'spectral_entropy', 'energy_band_0', 'energy_band_1', 'energy_band_2', 'energy_band_3', 'energy_band_4', 'energy_band_5', 'energy_band_6', 'energy_band_7']\n",
      "Features shape for model:  (26, 5, 9319)\n",
      "Features shape for model:  (5, 9319, 26)\n",
      "{0.0, 1.0}\n"
     ]
    }
   ],
   "source": [
    "from models.features_list import list_features\n",
    "\n",
    "results = []\n",
    "for record_number, data in test_data.items():\n",
    "    preds = compute_predictions_on_record(data, model, list_features)\n",
    "    formatted_preds = format_array_to_target_format(preds,record_number)\n",
    "    results.extend(formatted_preds)\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"../results/xgboost-balanced-cv.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
